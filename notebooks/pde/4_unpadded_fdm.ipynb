{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead583fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.sparse import diags, csc_matrix\n",
    "\n",
    "from dl4to.pde import SparseLinearSolver, PDESolver, FDMDerivatives, FDMAdjointDerivatives, FDMAssembly\n",
    "from dl4to.utils import get_σ_vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ee444-8c52-4634-b76e-803549125bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de21e6",
   "metadata": {},
   "source": [
    "# Unpadded FDM solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UnpaddedFDM(PDESolver):\n",
    "    \"\"\"\n",
    "    A PDE solver for linear elasticity that uses the finite differences method (FDM) with padding.\n",
    "    \"\"\"\n",
    "    def __init__(self, θ_min:float=1e-6, # The minimal value in the stiffness matrix. For numerical reasons we can not allow 0s, since they may lead to singular matrices.\n",
    "                 use_forward_differences:bool=True, # Whether to use forward differences or central differences.\n",
    "                 assemble_tensors_when_passed_to_problem:bool=True, # Whether the PDE solver methods pre-assembles any tensors or arrays before solving the PDE for a concrete problem.\n",
    "                 ):\n",
    "        self._θ_min = θ_min\n",
    "        self._linear_solver = SparseLinearSolver(use_umfpack=True, factorize=True)\n",
    "        self.use_forward_differences = use_forward_differences\n",
    "        self.assemble_tensors_when_passed_to_problem = assemble_tensors_when_passed_to_problem\n",
    "        self.assembled_tensors = False\n",
    "        super().__init__(assemble_tensors_when_passed_to_problem)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def problem(self):\n",
    "        return self._problem\n",
    "\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.problem.shape\n",
    "\n",
    "\n",
    "    @property\n",
    "    def Ω_dirichlet(self):\n",
    "        return self.problem.Ω_dirichlet\n",
    "\n",
    "\n",
    "    @property\n",
    "    def θ_min(self):\n",
    "        return self._θ_min\n",
    "\n",
    "\n",
    "    @property\n",
    "    def b(self):\n",
    "        return self._b\n",
    "\n",
    "\n",
    "    @property\n",
    "    def h(self):\n",
    "        return self.problem.h\n",
    "\n",
    "\n",
    "    @property\n",
    "    def linear_solver(self):\n",
    "        return self._linear_solver\n",
    "\n",
    "\n",
    "    def assemble_tensors(self, \n",
    "                         problem:\"dl4to.problem.Problem\" # The problem for which the tensors should be assembled.\n",
    "                        ):\n",
    "        \"\"\"\n",
    "        Assembles all FDM tensors from the problem object that can be pre-built without knowledge of the density distribution `θ`. This may take some time but makes future PDE evaluations for this problem much faster.\n",
    "        \"\"\"\n",
    "        self._problem = problem.clone()\n",
    "        GJ = lambda u: self._G(self._J(u))\n",
    "        self._Ω_dirichlet_diags = diags(self.Ω_dirichlet.flatten().int().numpy())\n",
    "        self._Jt_mat = FDMAssembly.assemble_operator(\n",
    "            operator=self._J, shape=self.shape, \n",
    "            Ω_dirichlet=self.Ω_dirichlet, \n",
    "            filter_shape=3).transpose()\n",
    "        self._GJ_mat = FDMAssembly.assemble_operator(\n",
    "            operator=GJ, shape=self.shape, Ω_dirichlet=self.Ω_dirichlet, filter_shape=3)\n",
    "        self._b = self._get_b()\n",
    "        self.assembled_tensors = True\n",
    "\n",
    "\n",
    "    def _get_θ_from_solution(self, solution, binary=False, clone=False):\n",
    "        if clone:\n",
    "            θ = solution.get_θ(binary).clone()\n",
    "        else:\n",
    "            θ = solution.get_θ(binary)\n",
    "        return θ\n",
    "\n",
    "\n",
    "    def _J(self, u, dirichlet=False):\n",
    "        J = lambda u: torch.cat([\n",
    "            FDMDerivatives.du_dx(u, self.h, self.use_forward_differences),\n",
    "            FDMDerivatives.du_dy(u, self.h, self.use_forward_differences),\n",
    "            FDMDerivatives.du_dz(u, self.h, self.use_forward_differences)\n",
    "        ], dim=0)\n",
    "\n",
    "        if dirichlet:\n",
    "            return FDMAssembly.apply_dirichlet_zero_columns_to_operator(J, self.Ω_dirichlet)(u)\n",
    "        return J(u)\n",
    "\n",
    "\n",
    "    def _J_adj(self, σ, dirichlet=False):\n",
    "        Jt = lambda σ: FDMAdjointDerivatives.du_dx_adj(σ[:3],  self.h, self.use_forward_differences) + \\\n",
    "                       FDMAdjointDerivatives.du_dy_adj(σ[3:6], self.h, self.use_forward_differences) + \\\n",
    "                       FDMAdjointDerivatives.du_dz_adj(σ[6:],  self.h, self.use_forward_differences)\n",
    "\n",
    "        if dirichlet:\n",
    "            return FDMAssembly.apply_dirichlet_zero_rows_to_operator(Jt, self.Ω_dirichlet)(σ)\n",
    "        return Jt(σ)\n",
    "\n",
    "\n",
    "    def _get_G(self):\n",
    "        ν = self.problem.ν\n",
    "\n",
    "        G = torch.tensor([\n",
    "            [1-ν,  0-0,  0-0,    0-0,  ν-0,  0-0,    0-0,  0-0,  ν-0],\n",
    "            [0-0, .5-ν,  0-0,   .5-ν,  0-0,  0-0,    0-0,  0-0,  0-0],\n",
    "            [0-0,  0-0, .5-ν,    0-0,  0-0,  0-0,   .5-ν,  0-0,  0-0],\n",
    "\n",
    "            [0-0, .5-ν,  0-0,   .5-ν,  0-0,  0-0,    0-0,  0-0,  0-0],\n",
    "            [ν-0,  0-0,  0-0,    0-0,  1-ν,  0-0,    0-0,  0-0,  ν-0],\n",
    "            [0-0,  0-0,  0-0,    0-0,  0-0, .5-ν,    0-0, .5-ν,  0-0],\n",
    "\n",
    "            [0-0,  0-0, .5-ν,    0-0,  0-0,  0-0,   .5-ν,  0-0,  0-0],\n",
    "            [0-0,  0-0,  0-0,    0-0,  0-0, .5-ν,    0-0, .5-ν,  0-0],\n",
    "            [ν-0,  0-0,  0-0,    0-0,  ν-0,  0-0,    0-0,  0-0,  1-ν]\n",
    "        ], dtype=self.problem.dtype)\n",
    "\n",
    "        G = G.to(self.problem.device)\n",
    "        return G / ((1 + ν) * (1 - 2 * ν))\n",
    "\n",
    "\n",
    "    def _G(self, ε):\n",
    "        ε = ε.type(self.problem.dtype)\n",
    "        return torch.einsum('ij, jlmn -> ilmn', self._get_G(), ε)\n",
    "\n",
    "\n",
    "    def _G_adj(self, σ):\n",
    "        σ = σ.type(self.problem.dtype)\n",
    "        return torch.einsum('ij, jlmn -> ilmn', self._get_G().t(), σ)\n",
    "\n",
    "\n",
    "    def _GJ(self, u, dirichlet=False):\n",
    "        apply_GJ = lambda u: self._G(self._J(u))\n",
    "\n",
    "        if dirichlet:\n",
    "            return FDMAssembly.apply_dirichlet_zero_columns_to_operator(apply_GJ, self.Ω_dirichlet)(u)\n",
    "        return apply_GJ(u)\n",
    "\n",
    "\n",
    "    def _GJ_adj(self, σ, dirichlet=False):\n",
    "        apply_GJ_adj = lambda σ: self._J_adj(self._G_adj(σ))\n",
    "\n",
    "        if dirichlet:\n",
    "            return FDMAssembly.apply_dirichlet_zero_rows_to_operator(apply_GJ_adj, self.Ω_dirichlet)(σ)\n",
    "        return apply_GJ_adj(σ)\n",
    "\n",
    "\n",
    "    def _apply_θp(self, σ, θ, p=1., normalize=True):\n",
    "        E = 1. if normalize else self.problem.E\n",
    "        E_min = E * self.θ_min\n",
    "        θ_ = E_min + θ**p * (E - E_min)\n",
    "        return θ_ * σ\n",
    "\n",
    "\n",
    "    def _assemble_θ(self, θ, p=1.):\n",
    "        E = 1.\n",
    "        E_min = E * self.θ_min\n",
    "        θ_ = E_min + (θ**p).flatten().repeat(9).detach().numpy() * (E - E_min)\n",
    "        return diags(θ_)\n",
    "\n",
    "\n",
    "    def _A(self, u, θ, dirichlet=True, p=1.):\n",
    "        u = u.view(3, θ.shape[-3], θ.shape[-2], θ.shape[-1])\n",
    "        y = self._GJ(u, dirichlet)\n",
    "        y = self._apply_θp(y, θ, p)\n",
    "        y = self._J_adj(y, dirichlet)\n",
    "\n",
    "        if dirichlet:\n",
    "            y[self.Ω_dirichlet] = u.clone()[self.Ω_dirichlet]\n",
    "        return y\n",
    "\n",
    "\n",
    "    def _A_adj(self, y, θ, dirichlet=True, p=1.):\n",
    "        y = y.view(3, θ.shape[-3], θ.shape[-2], θ.shape[-1])\n",
    "        u = self._J(y, dirichlet)\n",
    "        u = self._apply_θp(u, θ, p)\n",
    "        u = self._GJ_adj(u, dirichlet)\n",
    "\n",
    "        if dirichlet:\n",
    "            u[self.Ω_dirichlet] = y.clone()[self.Ω_dirichlet]\n",
    "        return u\n",
    "\n",
    "\n",
    "    def _assemble_A(self, θ, p=1.):\n",
    "        θ_mat = self._assemble_θ(θ, p)\n",
    "        A = self._Jt_mat.dot(θ_mat.dot(self._GJ_mat)) + self._Ω_dirichlet_diags\n",
    "        return csc_matrix(A)\n",
    "\n",
    "\n",
    "    def _get_b(self):\n",
    "        b = self.problem.F\n",
    "        b[self.Ω_dirichlet] = 0\n",
    "        b /= self.problem.E\n",
    "        return b\n",
    "\n",
    "\n",
    "    def _get_u(self, solution, p=1., binary=False):\n",
    "        if binary and (solution.u_binary is not None):\n",
    "            return solution.u_binary\n",
    "\n",
    "        if (not binary) and (solution.u is not None):\n",
    "            return solution.u\n",
    "\n",
    "        if not self.assembled_tensors:\n",
    "            self.assemble_tensors(solution.problem)\n",
    "\n",
    "        θ = self._get_θ_from_solution(solution, binary=binary, clone=True)\n",
    "        θ = θ.clamp(self.θ_min, 1)\n",
    "        A_op = lambda u, θ: self._A(u, θ, p=p)\n",
    "        A_mat = self._assemble_A(θ.cpu(), p)\n",
    "        u = self._linear_solver(θ.cpu(), A_op, self.b.flatten(), A_mat)\n",
    "        u = u.view(3, θ.shape[-3], θ.shape[-2], θ.shape[-1]).to(θ.device)\n",
    "\n",
    "        if binary:\n",
    "            solution.u_binary = u.clone()\n",
    "        else:\n",
    "            solution.u = u.clone()\n",
    "\n",
    "        return u\n",
    "\n",
    "\n",
    "    def _get_σ(self, solution, p=1., u=None, binary=False):\n",
    "        if u is None:\n",
    "            u = self._get_u(solution, p=p, binary=binary)\n",
    "\n",
    "        θ = self._get_θ_from_solution(solution, binary=binary, clone=False)\n",
    "        ε = self._J(u)\n",
    "        σ = self._G(ε)\n",
    "        σ = self._apply_θp(σ, θ, p=1., normalize=False)\n",
    "        return σ\n",
    "\n",
    "\n",
    "    def _stack_if_tensor_else_return_none(self, list):\n",
    "        if any(type(entry) is not torch.Tensor for entry in list):\n",
    "            return None\n",
    "        return torch.stack(list)\n",
    "\n",
    "\n",
    "    def solve_pde(self, \n",
    "                 solution:\"dl4to.solution.Solution\", # The solution for which the PDE should be solved.\n",
    "                 p:float=1., # The SIMP exponent when solving the PDE. Should usually be left at its default value of `1.`.\n",
    "                 binary:bool=False # Whether the densities in the solution should be binarized before solving the PDE.\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Solves the pde for `solution` and SIMP exponent `p`. Returns three `torch.Tensor` objects: displacements `u`, stresses `σ` and von Mises stresses `σ_vm`.\n",
    "        \"\"\"\n",
    "        u = self._get_u(solution, p=p, binary=binary)\n",
    "        σ = self._get_σ(solution, p=p, u=u, binary=binary)\n",
    "        σ_vm = get_σ_vm(σ)\n",
    "        return u, σ, σ_vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea580834-d329-47f9-88bf-ca25a13b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from dl4to.solution import Solution\n",
    "from dl4to.datasets import BasicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3374440-d4b6-4320-afef-0de7339e11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "atol = 1e-3\n",
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76093d60-5a5d-47d7-9a33-97bd9d37fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def get_rand_θ(problem):\n",
    "    θ = torch.rand(1,*problem.shape).clamp_(problem.pde_solver.θ_min, 1)\n",
    "    θ = θ**5\n",
    "\n",
    "    θ[problem.Ω_design == 0] = 0\n",
    "    θ[problem.Ω_design == 1] = 1\n",
    "    return θ\n",
    "\n",
    "\n",
    "def get_mock_objects(force=-1.5e5, resolution=35):\n",
    "    \"\"\"Mock Objects with Padding Depth 0\"\"\"\n",
    "    problem = BasicDataset(resolution=resolution, dtype=dtype).ledge(force_per_area=force)\n",
    "    problem.pde_solver = UnpaddedFDM()\n",
    "    θ = get_rand_θ(problem)\n",
    "    solution = Solution(problem, θ, enforce_θ_on_Ω_design=False)\n",
    "\n",
    "    shape_prod = np.prod(problem.shape)\n",
    "    u = torch.randn(3, *problem.shape, dtype=dtype)\n",
    "\n",
    "    return problem, problem.pde_solver, θ, solution, shape_prod, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c3838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 500 ms, sys: 30.9 ms, total: 531 ms\n",
      "Wall time: 554 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_create_FDM_object_and_get_properties():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    assert np.all(fdm.shape == problem.shape), fdm.shape\n",
    "    assert torch.all(fdm.Ω_dirichlet == problem.Ω_dirichlet)\n",
    "\n",
    "test_create_FDM_object_and_get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67df0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 549 ms, sys: 22.4 ms, total: 572 ms\n",
      "Wall time: 580 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_A_op_and_A_mat_sum_coincide():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "    u *= 1e-6\n",
    "\n",
    "    Au_op = fdm._A(u, θ, dirichlet=True)\n",
    "    Au_mat = torch.tensor(fdm._assemble_A(θ).dot(u.flatten()))\n",
    "    torch.allclose(Au_op.flatten().abs().sum(), Au_mat.flatten().abs().sum(), rtol=0), Au_op.flatten().abs().sum()\n",
    "\n",
    "\n",
    "test_that_A_op_and_A_mat_sum_coincide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01807856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 17.9 ms, total: 11.4 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_u_solves_linear_system():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    u = fdm(solution)[0]\n",
    "    Au = fdm._A(u, θ)\n",
    "    assert Au.shape == fdm.b.shape\n",
    "    assert torch.allclose(Au, fdm.b, atol=1e-2, rtol=0), torch.norm(Au - fdm.b)\n",
    "\n",
    "test_that_u_solves_linear_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf6463-f1e8-4da9-9b0c-2df9ccac3651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 52.2 ms, total: 12 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_u_solves_linear_system_in_norm():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    u = fdm(solution)[0]\n",
    "    norm_error = (fdm._A(u, θ) - fdm.b).norm()\n",
    "    norm_b = fdm.b.norm()\n",
    "    assert norm_error / norm_b < 1e-1, norm_error / norm_b\n",
    "\n",
    "test_that_u_solves_linear_system_in_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 31.4 ms, total: 22.9 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_u_grows_linearly_with_applied_forces():\n",
    "    force=-1.5e5\n",
    "    problem, fdm, θ, solution, shape_prod, _ = get_mock_objects(force=force)\n",
    "    u = fdm(solution)[0]\n",
    "\n",
    "    n = torch.randint(0, 100, (1,))\n",
    "    problem2, fdm2, θ2, solution2, shape_prod2, _ = get_mock_objects(force=force * n)\n",
    "\n",
    "    solution2 = Solution(problem2, θ)\n",
    "    u2 = fdm2(solution2)[0]\n",
    "\n",
    "    assert torch.allclose(n * u, u2)\n",
    "\n",
    "\n",
    "test_that_u_grows_linearly_with_applied_forces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e7c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 534 ms, sys: 24.1 ms, total: 558 ms\n",
      "Wall time: 572 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_shapes_are_correct():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    assert fdm._Jt_mat.shape == (3*shape_prod, 9*shape_prod)\n",
    "    assert fdm._GJ_mat.shape == (9*shape_prod, 3*shape_prod)\n",
    "    assert fdm._Ω_dirichlet_diags.shape == (3*shape_prod, 3*shape_prod)\n",
    "    assert fdm._get_G().shape == (9,9)\n",
    "    assert fdm._assemble_θ(θ).shape == (9*shape_prod, 9*shape_prod)\n",
    "    assert fdm._assemble_A(θ).shape == (3*shape_prod, 3*shape_prod)\n",
    "\n",
    "\n",
    "test_if_shapes_are_correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b9c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 608 ms, sys: 15.9 ms, total: 624 ms\n",
      "Wall time: 582 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_G_and_Gt_are_adjoint():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    u = torch.rand(9, *problem.shape, dtype=dtype)\n",
    "    v = torch.rand(9, *problem.shape, dtype=dtype)\n",
    "    Gu = fdm._G(u)\n",
    "    Gtv = fdm._G_adj(v)\n",
    "    assert torch.allclose(torch.dot(u.flatten(), Gtv.flatten()), torch.dot(Gu.flatten(), v.flatten()), atol=1e-2, rtol=0)\n",
    "\n",
    "test_if_G_and_Gt_are_adjoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697f8a8-eb7a-45c9-a077-0f6160783a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 65.7 ms, total: 16.3 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_J_and_Jt_are_adjoint():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects(resolution=50)\n",
    "\n",
    "    u = torch.rand(3, *problem.shape, dtype=dtype)\n",
    "    v = torch.rand(9, *problem.shape, dtype=dtype)\n",
    "    Ju = fdm._J(u, dirichlet=True)\n",
    "    Jtv = fdm._J_adj(v, dirichlet=True)\n",
    "    assert torch.allclose(torch.dot(u.flatten(), Jtv.flatten()), torch.dot(Ju.flatten(), v.flatten()), atol=1e-6, rtol=0)\n",
    "\n",
    "test_if_J_and_Jt_are_adjoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159d340-92d9-4c9f-a466-625ebee8b841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 520 ms, sys: 16 ms, total: 536 ms\n",
      "Wall time: 548 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_GJ_and_GJt_are_adjoint():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    u = torch.rand(3, *problem.shape, dtype=dtype)\n",
    "    v = torch.rand(9, *problem.shape, dtype=dtype)\n",
    "    GJu = fdm._GJ(u, dirichlet=True)\n",
    "    GJtv = fdm._GJ_adj(v, dirichlet=True)\n",
    "    assert torch.allclose(torch.dot(u.flatten(), GJtv.flatten()), torch.dot(GJu.flatten(), v.flatten()), atol=1e-2, rtol=0)\n",
    "\n",
    "test_if_GJ_and_GJt_are_adjoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b1d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 523 ms, sys: 12 ms, total: 535 ms\n",
      "Wall time: 544 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_A_and_At_are_adjoint():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    u = torch.rand(3, *problem.shape, dtype=dtype) / 1e5\n",
    "    v = torch.rand(3, *problem.shape, dtype=dtype) / 1e5\n",
    "    Au = fdm._A(u, θ , dirichlet=True)\n",
    "    Atv = fdm._A_adj(v, θ, dirichlet=True)\n",
    "    assert torch.allclose(torch.dot(u.flatten(), Atv.flatten()), torch.dot(Au.flatten(), v.flatten()), atol=1e-1, rtol=0)\n",
    "\n",
    "test_if_A_and_At_are_adjoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa735816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 514 ms, sys: 23.8 ms, total: 537 ms\n",
      "Wall time: 548 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_transposition_of_J_acts_as_adjoint_in_matrix_case():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    u = torch.rand(3*shape_prod, 1, dtype=dtype)\n",
    "    v = torch.rand(9*shape_prod, 1, dtype=dtype)\n",
    "    Jt = fdm._Jt_mat\n",
    "    J = fdm._Jt_mat.transpose()\n",
    "    Jtv = torch.tensor(Jt.dot(v))\n",
    "    Ju = torch.tensor(J.dot(u))\n",
    "    assert torch.allclose(torch.dot(u.flatten(), Jtv.flatten()), torch.dot(Ju.flatten(), v.flatten()), atol=1e-2)\n",
    "\n",
    "test_if_transposition_of_J_acts_as_adjoint_in_matrix_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c68fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 517 ms, sys: 8.01 ms, total: 525 ms\n",
      "Wall time: 532 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_transposition_of_J_acts_as_adjoint_when_using_forward_differences_in_matrix_case():\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    u = torch.rand(3*shape_prod, 1, dtype=dtype)\n",
    "    v = torch.rand(9*shape_prod, 1, dtype=dtype)\n",
    "    Jt = fdm._Jt_mat\n",
    "    J = fdm._Jt_mat.transpose()\n",
    "    Jtv = torch.tensor(Jt.dot(v))\n",
    "    Ju = torch.tensor(J.dot(u))\n",
    "    assert torch.allclose(torch.dot(u.flatten(), Jtv.flatten()), torch.dot(Ju.flatten(), v.flatten()), atol=1e-2)\n",
    "\n",
    "\n",
    "test_if_transposition_of_J_acts_as_adjoint_when_using_forward_differences_in_matrix_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 525 ms, total: 2.61 s\n",
      "Wall time: 987 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_assembly_of_GJ_is_correct(number=2):\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    GJ = lambda u: fdm._G(fdm._J(u))\n",
    "    GJ_op = FDMAssembly.apply_dirichlet_zero_columns_to_operator(GJ, fdm.Ω_dirichlet)\n",
    "    for _ in range(number):\n",
    "        x = torch.randn(3,*fdm.shape, dtype=dtype)\n",
    "        assert torch.allclose(torch.tensor(fdm._GJ_mat.todense(), dtype=dtype).mv(x.flatten()), GJ_op(x).flatten(), atol=1e-4)\n",
    "\n",
    "test_if_assembly_of_GJ_is_correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852ad6a-93f2-47bb-bf28-6a28770b441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 464 ms, total: 2.52 s\n",
      "Wall time: 901 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_if_assembly_of_Jt_is_correct(number=2):\n",
    "    problem, fdm, θ, solution, shape_prod, u = get_mock_objects()\n",
    "\n",
    "    J_op = FDMAssembly.apply_dirichlet_zero_columns_to_operator(fdm._J, fdm.Ω_dirichlet)\n",
    "\n",
    "    for _ in range(number):\n",
    "        x = torch.randn(3, *fdm.shape, dtype=dtype)\n",
    "        assert torch.allclose(torch.tensor(fdm._Jt_mat.transpose().todense(), dtype=dtype).mv(x.flatten()), J_op(x).flatten(), atol=1e-4)\n",
    "\n",
    "test_if_assembly_of_Jt_is_correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f4dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 263 ms, sys: 0 ns, total: 263 ms\n",
      "Wall time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_tensile_rod_solution_is_close_to_theoretical_case(tol=0.001):\n",
    "    force_per_area = -1.5e5\n",
    "    tensile_rod_problem = BasicDataset(resolution=30).tensile_rod(force_per_area=force_per_area)\n",
    "    tensile_rod_problem.pde_solver = UnpaddedFDM()\n",
    "    solution = tensile_rod_problem.trivial_solution\n",
    "    u_pde, σ, _ = solution.solve_pde()\n",
    "    relative_error = force_per_area / -σ[-1, 1, 1, 10].item()\n",
    "    assert 1. - tol < relative_error < 1. + tol, relative_error\n",
    "\n",
    "test_tensile_rod_solution_is_close_to_theoretical_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76804e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.75 s, sys: 17.8 ms, total: 4.77 s\n",
      "Wall time: 861 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_ledge_solution_is_close_to_theoretical_beam_displacement(tol=0.25):\n",
    "    force_per_area = -1.5e5\n",
    "    ledge_problem = BasicDataset(resolution=30).ledge(force_per_area=force_per_area)\n",
    "    ledge_problem.pde_solver = UnpaddedFDM(use_forward_differences=True)\n",
    "    solution = ledge_problem.trivial_solution\n",
    "    u_pde, _, _ = solution.solve_pde()\n",
    "    pde_max_displacement = u_pde.min().item()\n",
    "\n",
    "    #theoretical solution\n",
    "    l, b, h = ledge_problem.size[:]\n",
    "    I = (b*h**3)/12\n",
    "    force_per_length = force_per_area * b\n",
    "    E = ledge_problem.E\n",
    "    theoretical_max_displacement = force_per_length*(l**4) /(8*E*I)\n",
    "\n",
    "    relative_error = abs(theoretical_max_displacement / pde_max_displacement)\n",
    "    assert 1. - tol < relative_error < 1. + tol, relative_error\n",
    "\n",
    "test_that_ledge_solution_is_close_to_theoretical_beam_displacement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73558d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 47.9 ms, total: 10.1 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#slow\n",
    "#hide\n",
    "\n",
    "def test_displacements_dont_propagate_through_void__check_forks_displacements_in_the_top_are_at_least_5times_greater_than_in_the_bottom():\n",
    "    fork_problem = BasicDataset(resolution=35).fork()\n",
    "    fork_problem.pde_solver = UnpaddedFDM()\n",
    "    solution = fork_problem.trivial_solution\n",
    "    solution.θ *= 1e-6\n",
    "    u = solution.solve_pde()[0]\n",
    "\n",
    "    displacements_in_the_top = u[2, -1, :, -1].mean().abs()\n",
    "    displacements_in_the_bottom = u[2, -1, :, 1].mean().abs()\n",
    "\n",
    "    assert displacements_in_the_top > 5 * displacements_in_the_bottom, displacements_in_the_top / displacements_in_the_bottom\n",
    "\n",
    "test_displacements_dont_propagate_through_void__check_forks_displacements_in_the_top_are_at_least_5times_greater_than_in_the_bottom()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
