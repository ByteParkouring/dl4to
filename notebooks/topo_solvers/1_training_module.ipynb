{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b96aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp topo_solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from dl4to.plotting import plot_curve\n",
    "from dl4to.utils import create_dir, save_dict_as_txt, cast_to_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb9af9-8495-4658-982e-eb44ab74dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640c552-1005-4df0-835e-1e6c797eef39",
   "metadata": {},
   "source": [
    "# Training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528843a-4fe1-4a5e-a5b2-e610f5258552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class TrainModuleVerboseUtils:\n",
    "    @staticmethod\n",
    "    def print_current_losses(topo_solver_logs):\n",
    "        logs = topo_solver_logs\n",
    "        train_epoch    = logs[\"train_epochs\"][-1]\n",
    "        train_loss     = logs['train_losses'][-1]\n",
    "        train_loss_std = logs['train_losses_std'][-1]\n",
    "        print(f\"Train epoch: {train_epoch}. Train loss: {train_loss:.2}±{train_loss_std:.2}.\")\n",
    "        if \"val_losses\" in logs:\n",
    "            val_epoch    = logs[\"val_epochs\"][-1]\n",
    "            val_loss     = logs['val_losses'][-1]\n",
    "            val_loss_std = logs['val_losses_std'][-1]\n",
    "            print(f'Valid epoch: {val_epoch}. Valid loss: {val_loss:.2}±{val_loss_std:.2}.')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_train_and_val_losses(topo_solver_logs):\n",
    "        logs = topo_solver_logs\n",
    "        assert len(logs['train_epochs']) == len(logs['train_losses']) == len(topo_solver_logs['train_losses_std']), \"Training loss log inconsistent.\"\n",
    "        assert len(logs['val_epochs'])   == len(logs['val_losses'])   == len(topo_solver_logs['val_losses_std']), \"Validation loss log inconsistent.\"\n",
    "        fig, axes = plt.subplots(figsize=(7, 3), dpi=200, sharex=False)\n",
    "        plot_curve(\n",
    "            x=logs['train_epochs'],\n",
    "            y=logs['train_losses'],\n",
    "            y_std=logs['train_losses_std'],\n",
    "            label=\"Training loss\",\n",
    "            axis=axes,\n",
    "            show_all_xticks=False\n",
    "        )\n",
    "        plot_curve(\n",
    "            x=logs['val_epochs'],\n",
    "            y=logs['val_losses'],\n",
    "            y_std=logs['val_losses_std'],\n",
    "            label=\"Validation loss\",\n",
    "            axis=axes,\n",
    "            show_all_xticks=False\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a08fc-08fb-4a97-839e-ee2b3e6b9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class EpochLossGetter:\n",
    "    def __init__(self, topo_solver):\n",
    "        self.solver = topo_solver\n",
    "        self.model = self.solver.model if hasattr(self.solver, 'model') else None\n",
    "        self.criterion = self.solver.criterion  if hasattr(self.solver, 'criterion') else None\n",
    "        self.optimizer = self.solver.optimizer if hasattr(self.solver, 'optimizer') else None\n",
    "        self._check_attr()\n",
    "\n",
    "\n",
    "    def _push_to_device(self, solutions):\n",
    "        for solution in solutions:\n",
    "            solution.device = self.solver.device\n",
    "\n",
    "\n",
    "    def _check_attr(self):\n",
    "        if self.model is None:\n",
    "            raise AttributeError(\"TrainModule cannot train w/o a model!\")\n",
    "        if not self.solver.trainable:\n",
    "            raise AttributeError(f\"Topo solver `{self.solver.name}` is not trainable.\")\n",
    "        if self.criterion is None:\n",
    "            raise AttributeError(\"TrainModule cannot find a criterion!\")\n",
    "\n",
    "\n",
    "    def _run_batch(self, problems_or_solutions, gt_solutions, train):\n",
    "        self._push_to_device(gt_solutions)\n",
    "        solutions = self.solver(problems_or_solutions, eval_mode=not train)\n",
    "        losses = self.solver.criterion(solutions, gt_solutions, binary=False)\n",
    "        loss = losses.mean()\n",
    "        if train:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        losses = list(losses.detach().cpu().numpy().astype(np.float64))\n",
    "        return losses\n",
    "\n",
    "\n",
    "    def __call__(self, dataloader, train):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        losses = []\n",
    "        for problems_or_solutions, gt_solutions in dataloader:\n",
    "            losses += self._run_batch(problems_or_solutions=problems_or_solutions, gt_solutions=gt_solutions, train=train)\n",
    "        self.model.eval()\n",
    "        return np.mean(losses), np.std(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc65071-558d-40d1-ae92-ecd2da7629b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainModule:\n",
    "    \"\"\"\n",
    "    A class that contains methods for the training of topo solvers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    topo_solver : dl4to.TopoSolver\n",
    "        The trainable topo solver that should be trained.\n",
    "    \"\"\"\n",
    "    def __init__(self, topo_solver):\n",
    "        self.solver = topo_solver\n",
    "        self.epoch_module = EpochLossGetter(self.solver)\n",
    "\n",
    "\n",
    "    def _train_epoch(self, dataloader, epoch):\n",
    "        train_loss, train_loss_std = self.epoch_module(dataloader=dataloader, train=True)\n",
    "        self.solver.logs['train_epochs'].append(epoch)\n",
    "        self.solver.logs['train_losses'].append(train_loss)\n",
    "        self.solver.logs['train_losses_std'].append(train_loss_std)\n",
    "\n",
    "\n",
    "    def _eval_epoch(self, dataloader, epoch, verbose):\n",
    "        val_loss, val_loss_std = self.epoch_module(dataloader=dataloader, train=False)\n",
    "        self.solver.logs['val_epochs'].append(epoch)\n",
    "        self.solver.logs['val_losses'].append(val_loss)\n",
    "        self.solver.logs['val_losses_std'].append(val_loss_std)\n",
    "\n",
    "        if verbose:\n",
    "            TrainModuleVerboseUtils.print_current_losses(topo_solver_logs=self.solver.logs)\n",
    "\n",
    "\n",
    "    def _write_solver_to_disc(self, dir_path, prefix, tick):\n",
    "        self.solver.logs['duration'] = time.time() - tick\n",
    "        torch.save(self.solver, f'{dir_path}/{prefix}_solver.pt')\n",
    "        save_dict_as_txt(self.solver.logs, dir_path=dir_path, file_name=f'{prefix}_logs')\n",
    "\n",
    "\n",
    "    def _write_solver_to_disc_if_best_yet(self, dir_path, tick):\n",
    "        val_losses = self.solver.logs['val_losses']\n",
    "        val_loss = val_losses[-1]\n",
    "        best_val_loss = min(val_losses)\n",
    "        if val_loss > best_val_loss:\n",
    "            return best_val_loss\n",
    "        self._write_solver_to_disc(dir_path=dir_path, prefix=\"best\", tick=tick)\n",
    "        return val_loss\n",
    "\n",
    "\n",
    "    def _create_folder_and_save_topo_solver_args(self, root, epochs, patience):\n",
    "        dir_path = create_dir(name=f\"train_results\", path=root, prepend_date=False)\n",
    "        my_dict = {\n",
    "            'root': root,\n",
    "            'epochs': epochs,\n",
    "            'patience': patience,\n",
    "        }\n",
    "        args_dict = self.solver.get_args_as_dict()\n",
    "        args_dict = {**args_dict, **my_dict}\n",
    "        save_dict_as_txt(my_dict=args_dict, dir_path=dir_path, file_name=\"solver_description\")\n",
    "\n",
    "        return dir_path\n",
    "\n",
    "\n",
    "    def _get_best_epoch(self):\n",
    "        val_losses = self.solver.logs['val_losses']\n",
    "        val_epochs = self.solver.logs['val_epochs']\n",
    "        assert len(val_losses) == len(val_epochs), \"TrainModule: len(val_losses) != len(val_epochs)\"\n",
    "        best_val_loss_idx = np.argmin(val_losses)\n",
    "        return val_epochs[best_val_loss_idx]\n",
    "\n",
    "\n",
    "    def _input_check(self, dataloader_val, validation_interval, patience):\n",
    "        if dataloader_val is not None:\n",
    "            return\n",
    "        if validation_interval is not None:\n",
    "            raise ValueError(\"You can not validate without a dataloader_val. Set validation_interval=None or add dataloader_val.\")\n",
    "        if patience != \"inf\":\n",
    "            raise ValueError(\"patience != 'inf' requires dataloader_val != None.\")\n",
    "\n",
    "\n",
    "    def __call__(\n",
    "        self, root, dataloader_train,\n",
    "        dataloader_val=None, epochs=100, \n",
    "        validation_interval=10, verbose=True,\n",
    "        patience=None):\n",
    "        \"\"\"\n",
    "        Run the training for the topo solver.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        root : str\n",
    "            The directory where the training results should be saved.\n",
    "        dataloader_train : torch.utils.data.Dataloader\n",
    "            The dataloader that contains the training data.\n",
    "        dataloader_val : torch.utils.data.Dataloader\n",
    "            The dataloader that contains the validation data.\n",
    "        epochs : int\n",
    "            The maximal number of training epochs.\n",
    "        validation_interval : int\n",
    "            The number of epochs after which a validation step is performed and printed.\n",
    "        verbose : bool\n",
    "            Whether to print information on the current training status, like the current loss and epoch.\n",
    "        patience : int\n",
    "            If the validation score does not improve for `patience` epochs in a row, then the training is stopped and the best model is used.\n",
    "        \"\"\"\n",
    "        if patience is None:\n",
    "            patience = \"inf\"\n",
    "        self._input_check(dataloader_val, validation_interval, patience)\n",
    "        dir_path = self._create_folder_and_save_topo_solver_args(root, epochs, patience)\n",
    "        tick = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self._train_epoch(dataloader_train, epoch)\n",
    "            validation_free_epoch = (validation_interval is None) or ((epoch % validation_interval != 0) and (epoch != epochs - 1))\n",
    "            if validation_free_epoch:\n",
    "                continue\n",
    "            self._eval_epoch(dataloader_val, epoch, verbose)\n",
    "            self._write_solver_to_disc_if_best_yet(dir_path, tick)\n",
    "            if patience != \"inf\":\n",
    "                we_have_lost_hope = epoch > self._get_best_epoch() + patience\n",
    "                if we_have_lost_hope:\n",
    "                    break\n",
    "        self._write_solver_to_disc(dir_path=dir_path, prefix=\"last\", tick=tick)\n",
    "        if verbose:\n",
    "            TrainModuleVerboseUtils.plot_train_and_val_losses(topo_solver_logs=self.solver.logs)\n",
    "        print(f'Finished training after {epoch + 1} epochs.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab99ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from dl4to.criteria import WeightedBCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class MockTrainableTopoSolver:\n",
    "    def __init__(self):\n",
    "        self.model = torch.nn.Sequential()\n",
    "        self.logs = None\n",
    "        self.optimizer = None\n",
    "        self.criterion = WeightedBCE()\n",
    "        self.metrics = None\n",
    "        self.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3528ab-f2ba-490c-bff9-30ee77186637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 µs, sys: 23 µs, total: 147 µs\n",
      "Wall time: 154 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_we_can_instanciate():\n",
    "    topo_solver = MockTrainableTopoSolver()\n",
    "    train_module = TrainModule(topo_solver)\n",
    "\n",
    "\n",
    "test_that_we_can_instanciate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
