{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065f4267-9cc3-4d0d-a888-f64d7f555c0c",
   "metadata": {},
   "source": [
    "# Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4dee2-81b5-40a6-a81b-26e5b8649f5a",
   "metadata": {},
   "source": [
    "In this tutorial you learn how to\n",
    "- load datasets, e.g., the SELTO datasets\n",
    "- how to use pyvista plotting\n",
    "- work with datasets\n",
    "- get dataloaders from datasets\n",
    "- create custom datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920c72c-ae46-4ab4-87c9-21b52282d5f9",
   "metadata": {},
   "source": [
    "### The Basic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49628e41-014f-411f-b200-1d39269fed85",
   "metadata": {},
   "source": [
    "The ledge problem that we created manually by hand in the last tutorial is actually part of a dataset, the so-called \"Basic dataset\". This dataset contains examples of TO problems that we found in the literature on 3d topology optimization. \n",
    "\n",
    "We can reproduce our ledge problem by importing the BasicDataset class and calling the \"ledge()\" function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f55d2-3f13-4683-92cb-36601d8709a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "from dl4to.datasets import BasicDataset\n",
    "\n",
    "problem = BasicDataset(resolution=40).ledge(force_per_area=-1.25e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d0a505-2c5c-4145-a55e-1aa76336d2b5",
   "metadata": {},
   "source": [
    "Note that the force is a bit different than in the previous example, because here ledge gets `force_per_area` as input, whereas in the last tutorial it was `force_per_volume`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bf278-710c-4fc8-99c3-69b98f178adb",
   "metadata": {},
   "source": [
    "The Basic dataset contains several other TO problems, e.g., including the classical cantilever problem. For more information on that we refer to the documentation of the Basic dataset class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98a9db-d5d3-4dbc-8cba-a5bf2d4aada4",
   "metadata": {},
   "source": [
    "### The SELTO datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99a777-14b0-49c9-a370-7ab17f1b9543",
   "metadata": {},
   "source": [
    "If you have read our SELTO paper [1], then you know that we have published two large three-dimensional datasets with almost $10.000$ samples in total. The two datasets are called \"disc\" and \"sphere\". Furthermore, they can both be divided into two subsets with different load cases, so we in fact even have four datasets to work with! We call these subsets \"simple\" and \"complex\", i.e., we refer to them as \"disc simple\", \"disc complex\", \"sphere simple\" and \"sphere complex\". \n",
    "\n",
    "You can see the specifications of our SELTO datasets in the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943b52d-783a-4346-bd28-6aae0c82c48e",
   "metadata": {},
   "source": [
    "![selto_dataset](https://dl4to.github.io/dl4to/images/2_selto_dataset_information.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee7199-bb98-43d3-a0f7-cddc37e95c17",
   "metadata": {},
   "source": [
    "All four datasets are already split into training and validation subsets. Let's start with loading the validation dataset of \"disc simple\". The dataset will be downloaded from Zenodo [2], so you need to specify a root where the dataset should be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e660f2e-bda4-4ee8-9205-84a063cb92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 files.\n",
      "importing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc2f9a4290f4a67b5f25521bbf2b174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#ignore\n",
    "from dl4to.datasets import SELTODataset\n",
    "\n",
    "dataset = SELTODataset(root='/localdata/dl4to_dataset/', \n",
    "                       name='disc_simple', \n",
    "                       train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3353bd5-7548-446a-a7e8-b82f92ee41ae",
   "metadata": {},
   "source": [
    "We can print basic information on the current dataset via `dataset.info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7cca1-12fa-4514-b08f-a3f54cb858ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This TopoDataset is called disc_simple_test and contains 200 samples.\n"
     ]
    }
   ],
   "source": [
    "#ignore\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1835f2-9798-4b3b-a364-cdc8d6536e7d",
   "metadata": {},
   "source": [
    "All our datasets inherit from \"torch.utils.data.Dataset\". so if you know PyTorch you can work with them the way that you are used to.\n",
    "\n",
    "We can check if the dataset is indeed $200$ samples large, like the above table claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ea468-9781-4857-a73e-440b77d35b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignore\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e2434-6a10-4791-970b-796a7b25e56e",
   "metadata": {},
   "source": [
    "If you want to use the full (combined) disc dataset, then you can load both \"disc simple\" and \"disc complex\" individually and simply add them up with the \"+\" sign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276b377-f232-4acf-90c9-ca80e2f8f597",
   "metadata": {},
   "source": [
    "The SELTO datasets contain not only problems, but also a ground truth for each problem. We can access the first problem in the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2de51-fa57-4a76-bfec-b53deb2d34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "problem, solution = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c487a-4b1d-46b6-8b13-1131a94a17fd",
   "metadata": {},
   "source": [
    "Plotting of the problem object explains why this dataset is called disc: The design space has the shape of a flat disc. Analogously, the design shape of the sphere datasets has the shape of a semi sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32c112-3e10-4817-b4be-102805196280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "camera_position = (0, 0.06, 0.12)\n",
    "problem.plot(camera_position=camera_position,\n",
    "             display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4ba07-f233-4b34-bddb-531e04425fd4",
   "metadata": {},
   "source": [
    "![dirichlet](https://dl4to.github.io/dl4to/images/2_dirichlet.png)\n",
    "![design](https://dl4to.github.io/dl4to/images/2_design.png)\n",
    "![force_locs](https://dl4to.github.io/dl4to/images/2_force_locs.png)\n",
    "![force_dirs](https://dl4to.github.io/dl4to/images/2_force_dirs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175ebae-52f9-4218-a5ae-d6ea144c9410",
   "metadata": {},
   "source": [
    "We also observe that this problem has a load case of only one single point of attack. This is the case with the \"simple\" datasets. If we had chosen the \"disc complex\" dataset above, then we would have two individual points of attack.\n",
    "\n",
    "The ground truth solution to the problem looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb2c42-4cd5-40e0-a709-5cd311809f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "solution.plot(camera_position=camera_position,\n",
    "              display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb5310-8163-4eaf-ae27-60eed547d0ab",
   "metadata": {},
   "source": [
    "![gt_solution](https://dl4to.github.io/dl4to/images/2_gt_solution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f891342-46f7-445c-b295-87d81d9997b7",
   "metadata": {},
   "source": [
    "### Pyvista plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1959f2d-ff82-4cdc-9111-1d2e17bbd735",
   "metadata": {},
   "source": [
    "As an alternative to the standard [plotly](https://plotly.com/) plotting interface it is also possible to use [pyvista](https://docs.pyvista.org/version/stable/). Pyvista plotting may lead to better looking visualizations than plotly. This is mainly due to the fact, that pyvista integrates Taubin smoothing [3], which is a volume-preserving smoothing algorithm. However, the pyvista interface also has its downsides: In our experiments we found that only the backend `pythreejs` worked for us. This backend unfortunately currently does not support several basic functionalities. This includes for instance the display of color bars and plot titles as well as the option to save generated plots. Therefore, the plots need to be saved via manual screenshots. We still decided to leave pyvista a part of the DL4TO library, since the visualizations may be better looking for publications than the default plotly interface. it is possible that the missing features will be added in the future, if pyvista adds them to their `pythreejs` backend or we somehow manage to make a different backend work.\n",
    "\n",
    "We can use pyvista for plotting by specifying `use_pyvista=True` and we can set the number of Taubin smoothing iterations via the parameter `smooth_iters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0b33b-bfdd-4be7-86dd-84b2191dcd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "solution.plot(camera_position=camera_position,\n",
    "              use_pyvista=True,\n",
    "              smooth_iters=100,\n",
    "              window_size=(600,600),\n",
    "              display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564a555-cfaf-480c-8433-0f9a87c4596d",
   "metadata": {},
   "source": [
    "![pyvista_gt_solution](https://dl4to.github.io/dl4to/images/2_pyvista_gt_solution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0d939-d361-43a2-b006-09e411544e17",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc0075-33cd-491b-bc55-7d5a394c266f",
   "metadata": {},
   "source": [
    "Since all datasets inherit from the PyTorch Dataset class, we can easily use PyTorch dataloaders. We implemented a function that makes it even easier for you: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511559d-6f58-411c-a071-369b96cb72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignore\n",
    "from dl4to.utils import get_dataloader\n",
    "\n",
    "dataloader = get_dataloader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "type(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf778d0-dfdc-4dc4-871b-9a88acb04400",
   "metadata": {},
   "source": [
    "This dataloader object automatically shuffles the dataset if desired and divides it into batches. If you prefer to use only a single batch which has the size of the full dataset, then you can do this by specifying \"batch_size=-1\".\n",
    "\n",
    "Let's iterate over a dataloader and check if the sizes of each batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4598b8f-063d-4f37-a8ef-a6a276adc8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "64\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#ignore\n",
    "for problems, solutions in dataloader:\n",
    "    print(len(problems))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22ada4-65c6-438c-8b2e-ec8c77570edc",
   "metadata": {},
   "source": [
    "There are less than $64$ samples in the last batch because there were not enough samples left in the dataset to make up the full batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cc1a2-20f6-4011-8edc-5a2a03a075cc",
   "metadata": {},
   "source": [
    "### Create and load custom datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f697dd-76a5-4c6a-94aa-74b128dbb118",
   "metadata": {},
   "source": [
    "The easiest way to create a dataset is to create it from a list. This list either contains only problems or tuples of problems and ground truths. You can then turn that list into a TopoDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517fa5d-9744-440c-8260-748235f2ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "from dl4to.datasets import TopoDataset\n",
    "\n",
    "my_list = [] # you can fill this list with either problems or with tuples (problem, solution)\n",
    "dataset = TopoDataset(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670cd57-ee7b-46a3-822f-ce93f7aa1ea0",
   "metadata": {},
   "source": [
    "You can save and load datasets just like regular PyTorch objects via `torch.save(dataset, \"dataset.pt\")` and `dataset = torch.load(\"dataset.pt\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f632a5-5bda-40e3-af3e-20ea3651094a",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e5f9e-dde6-4921-91de-0a3c3c669cc8",
   "metadata": {},
   "source": [
    "[1] Dittmer, Sören, et al. \"SELTO: Sample-Efficient Learned Topology Optimization.\" arXiv preprint arXiv:2209.05098 (2023).\n",
    "\n",
    "[2] Dittmer, Sören, et al. \"SELTO Dataset\". Zenodo. https://doi.org/10.5281/zenodo.7781392 (2023)\n",
    "\n",
    "[3] Taubin, Gabriel. \"Curve and surface smoothing without shrinkage.\" Proceedings of IEEE international conference on computer vision. IEEE, 1995."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
