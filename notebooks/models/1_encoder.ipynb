{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662aefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a71f1",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dl4to.models import ConvolutionalBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2276cd3-f380-4bcb-908f-6a5c78966f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42988160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EncodingBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines a single encoding block for an encoder.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels:int, # The number of input channels.\n",
    "        out_channels_first:int, # The number of output channels after the first encoding step.\n",
    "        dimensions:int, # The number of dimensions to consider. Possible options are 2 and 3.\n",
    "        normalization:str, # The type of normalization to use. Possible options include \"batch\", \"layer\" and \"instance\".\n",
    "        pooling_type:str, # The type of pooling to use.\n",
    "        pooling_kernel_size:int, # The size of the pooling kernel.\n",
    "        preactivation:bool=False, # Whether to use preactivations.\n",
    "        is_first_block:bool=False, # Whether this is the first block of an encoder.\n",
    "        residual:bool=False, # Whether the encoder should be a residual network.\n",
    "        use_padding:bool=False, # Whether to use padding.\n",
    "        padding_mode:str='zeros', # The type of padding to use.\n",
    "        activation:str='ReLU', # The activation function that should be used.\n",
    "        dilation:int=None, # The amount of dilation that should be used.\n",
    "        dropout:float=0., # The dropout rate.\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.preactivation = preactivation\n",
    "        self.normalization = normalization\n",
    "\n",
    "        self.residual = residual\n",
    "\n",
    "        if is_first_block:\n",
    "            normalization = None\n",
    "            preactivation = None\n",
    "        else:\n",
    "            normalization = self.normalization\n",
    "            preactivation = self.preactivation\n",
    "\n",
    "        self.conv1 = ConvolutionalBlock(\n",
    "            dimensions=dimensions,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels_first,\n",
    "            normalization=normalization,\n",
    "            preactivation=preactivation,\n",
    "            use_padding=use_padding,\n",
    "            padding_mode=padding_mode,\n",
    "            activation=activation,\n",
    "            dilation=dilation,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        if dimensions == 2:\n",
    "            out_channels_second = out_channels_first\n",
    "        elif dimensions == 3:\n",
    "            out_channels_second = 2 * out_channels_first\n",
    "\n",
    "        self.conv2 = ConvolutionalBlock(\n",
    "            dimensions=dimensions,\n",
    "            in_channels=out_channels_first,\n",
    "            out_channels=out_channels_second,\n",
    "            normalization=self.normalization,\n",
    "            preactivation=self.preactivation,\n",
    "            use_padding=use_padding,\n",
    "            activation=activation,\n",
    "            dilation=dilation,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        if residual:\n",
    "            self.conv_residual = ConvolutionalBlock(\n",
    "                dimensions=dimensions,\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels_second,\n",
    "                kernel_size=1,\n",
    "                normalization=None,\n",
    "                activation=None\n",
    "            )\n",
    "\n",
    "        self._set_downsampling_layer(dimensions, pooling_type, kernel_size=pooling_kernel_size)\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                x:torch.Tensor # the input to the encoding block.\n",
    "               ):\n",
    "        \"\"\"\n",
    "        The forward pass of the encoding block.\n",
    "        Returns a list of `torch.Tensors` that define the outputs of the skip connections, and a `torch.Tensor` that is the output of the encoding block.\n",
    "        \"\"\"\n",
    "        if self.residual:\n",
    "            connection = self.conv_residual(x)\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x += connection\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "\n",
    "        if self.downsample is None:\n",
    "            return x\n",
    "\n",
    "        skip_connection = x\n",
    "        x = self.downsample(x)\n",
    "        return x, skip_connection\n",
    "\n",
    "\n",
    "    @property\n",
    "    def out_channels(self):\n",
    "        return self.conv2.conv_layer.out_channels\n",
    "\n",
    "\n",
    "    def _set_downsampling_layer(self, dimensions, pooling_type, kernel_size, stride=2):\n",
    "        if pooling_type is None:\n",
    "            self.downsample = None\n",
    "        else:\n",
    "            class_name = '{}Pool{}d'.format(pooling_type.capitalize(), dimensions)\n",
    "            class_ = getattr(nn, class_name)\n",
    "            self.downsample = class_(kernel_size, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeab955-966f-496c-a0cf-4a12e36d42a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EncodingBlock.forward\" class=\"doc_header\"><code>EncodingBlock.forward</code><a href=\"__main__.py#L80\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EncodingBlock.forward</code>(**`x`**:`Tensor`)\n",
       "\n",
       "The forward pass of the encoding block.\n",
       "Returns a `torch:Tensor` that defines the skip connections, and a `torch.Tensor` that is the output of the encoding block.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`x`**|`Tensor`||the input to the encoding block.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EncodingBlock.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb378ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines an encoder that can be used for the construction of UNets [1]. \n",
    "    An encoder is a neural network that takes the input, and outputs a feature vector for each input sample.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels:int, # The number of input channels.\n",
    "        out_channels_first:int, # The number of output channels after the first encoding step.\n",
    "        dimensions:int, # The number of dimensions to consider. Possible options are 2 and 3.\n",
    "        pooling_type:str, # The type of pooling to use.\n",
    "        num_encoding_blocks:int, # The number of encoding blocks.\n",
    "        normalization:str, # The type of normalization to use. Possible options include \"batch\", \"layer\" and \"instance\".\n",
    "        pooling_kernel_size:int, # The size of the pooling kernel.\n",
    "        preactivation:bool=False, # Whether to use preactivations.\n",
    "        residual:bool=False, # Whether the encoder should be a residual network.\n",
    "        use_padding:bool=False, # Whether to use padding.\n",
    "        padding_mode:str='zeros', # The type of padding to use.\n",
    "        activation:str='ReLU', # The activation function that should be used.\n",
    "        initial_dilation:int=None, # The amount of dilation that should be used in the first encoding block.\n",
    "        dropout:float=0. # The dropout rate.\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if len(pooling_kernel_size) != dimensions:\n",
    "            raise ValueError('Length of pooling_kernel_size and dimension do not coincide!')\n",
    "\n",
    "        self.encoding_blocks = nn.ModuleList()\n",
    "        self.dilation = initial_dilation\n",
    "        is_first_block = True\n",
    "\n",
    "        for _ in range(num_encoding_blocks):\n",
    "            encoding_block = EncodingBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels_first=out_channels_first,\n",
    "                dimensions=dimensions,\n",
    "                normalization=normalization,\n",
    "                pooling_type=pooling_type,\n",
    "                preactivation=preactivation,\n",
    "                is_first_block=is_first_block,\n",
    "                residual=residual,\n",
    "                use_padding=use_padding,\n",
    "                padding_mode=padding_mode,\n",
    "                activation=activation,\n",
    "                dilation=self.dilation,\n",
    "                dropout=dropout,\n",
    "                pooling_kernel_size=pooling_kernel_size\n",
    "            )\n",
    "\n",
    "            is_first_block = False\n",
    "            self.encoding_blocks.append(encoding_block)\n",
    "\n",
    "            if dimensions == 2:\n",
    "                in_channels = out_channels_first\n",
    "                out_channels_first = in_channels * 2\n",
    "            elif dimensions == 3:\n",
    "                in_channels = 2 * out_channels_first\n",
    "                out_channels_first = in_channels\n",
    "\n",
    "            if self.dilation is not None:\n",
    "                self.dilation *= 2\n",
    "\n",
    "\n",
    "    @property\n",
    "    def out_channels(self):\n",
    "        return self.encoding_blocks[-1].out_channels\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                x:torch.Tensor # The input of the encoder.\n",
    "               ):\n",
    "        \"\"\"\n",
    "        The forward pass of the encoder. \n",
    "        Returns a list of `torch.Tensors` that define the outputs of the skip connections, and a `torch.Tensor` that is the output of the encoder.\n",
    "        \"\"\"\n",
    "        skip_connections = []\n",
    "\n",
    "        for encoding_block in self.encoding_blocks:\n",
    "            x, skip_connection = encoding_block(x)\n",
    "            skip_connections.append(skip_connection)\n",
    "\n",
    "        return skip_connections, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7e3a9-18fb-495e-8c54-74f6f08ca71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Encoder.forward\" class=\"doc_header\"><code>Encoder.forward</code><a href=\"__main__.py#L70\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Encoder.forward</code>(**`x`**:`Tensor`)\n",
       "\n",
       "The forward pass of the encoder. \n",
       "Returns a `torch:Tensor` that defines the skip connections, and a `torch.Tensor` that is the output of the encoder.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`x`**|`Tensor`||The input of the encoder.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Encoder.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0acbda-f11d-4f06-b37f-462fbcdafe53",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda8181-c0e1-4b1f-be25-c70295817911",
   "metadata": {},
   "source": [
    "[1] Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0d1b5-bbac-47bf-973f-2a83a83424f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import torch\n",
    "import hypothesis.strategies as st\n",
    "from hypothesis import given, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7cdd01-6c17-4902-b52e-f9c7453d4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "st_n_channels = st.integers(min_value=1, max_value=50)\n",
    "\n",
    "st_input_shape = st.tuples(\n",
    "    st.integers(min_value=32, max_value=64),\n",
    "    st.integers(min_value=32, max_value=64),\n",
    "    st.integers(min_value=32, max_value=64)\n",
    ")\n",
    "\n",
    "st_out_channels_first = st.integers(min_value=1, max_value=2)\n",
    "st_num_encoding_blocks = st.integers(min_value=1, max_value=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe27ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.48 s, sys: 31.1 ms, total: 2.51 s\n",
      "Wall time: 354 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "@given(\n",
    "    n_channels=st_n_channels,\n",
    "    input_shape=st_input_shape,\n",
    "    out_channels_first=st_out_channels_first,\n",
    "    num_encoding_blocks=st_num_encoding_blocks\n",
    ")\n",
    "@settings(max_examples=2, deadline=None)\n",
    "def test_output_shapes_in_3d_without_padding(\n",
    "    n_channels,\n",
    "    input_shape,\n",
    "    out_channels_first,\n",
    "    num_encoding_blocks\n",
    "):\n",
    "    model = Encoder(\n",
    "        in_channels=n_channels,\n",
    "        out_channels_first=out_channels_first,\n",
    "        dimensions=3,\n",
    "        pooling_type='max',\n",
    "        num_encoding_blocks=num_encoding_blocks,\n",
    "        normalization=None,\n",
    "        pooling_kernel_size=[2, 2, 2],\n",
    "        use_padding=False,\n",
    "    ).eval()\n",
    "\n",
    "    x = torch.rand(1, n_channels, *input_shape)\n",
    "    output_shape = list(input_shape)\n",
    "\n",
    "    for _ in range(num_encoding_blocks):\n",
    "        output_shape[0] = int((output_shape[0] - 4) / 2)\n",
    "        output_shape[1] = int((output_shape[1] - 4) / 2)\n",
    "        output_shape[2] = int((output_shape[2] - 4) / 2)\n",
    "\n",
    "    assert model(x)[1].shape == (1, out_channels_first * 2**num_encoding_blocks, *output_shape)\n",
    "\n",
    "\n",
    "test_output_shapes_in_3d_without_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.42 s, sys: 40.3 ms, total: 2.46 s\n",
      "Wall time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "@given(\n",
    "    n_channels=st_n_channels,\n",
    "    input_shape=st_input_shape,\n",
    "    out_channels_first=st_out_channels_first,\n",
    "    num_encoding_blocks=st_num_encoding_blocks\n",
    ")\n",
    "@settings(max_examples=2, deadline=None)\n",
    "def test_output_shapes_with_padding(\n",
    "    n_channels,\n",
    "    input_shape,\n",
    "    out_channels_first,\n",
    "    num_encoding_blocks\n",
    "):\n",
    "    model = Encoder(\n",
    "        in_channels=n_channels,\n",
    "        out_channels_first=out_channels_first,\n",
    "        dimensions=3,\n",
    "        pooling_type='max',\n",
    "        num_encoding_blocks=num_encoding_blocks,\n",
    "        normalization=None,\n",
    "        pooling_kernel_size=[2, 2, 2],\n",
    "        use_padding=True,\n",
    "    ).eval()\n",
    "\n",
    "    x = torch.rand(1, n_channels, *input_shape)\n",
    "    output_shape = list(input_shape)\n",
    "\n",
    "    output_shape[0] = int(input_shape[0] / 2**num_encoding_blocks)\n",
    "    output_shape[1] = int(input_shape[1] / 2**num_encoding_blocks)\n",
    "    output_shape[2] = int(input_shape[2] / 2**num_encoding_blocks)\n",
    "    assert model(x)[1].shape == (1, out_channels_first * 2**num_encoding_blocks, *output_shape)\n",
    "\n",
    "\n",
    "test_output_shapes_with_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711522d-c0ad-4d68-9bfd-ba33b2968163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
