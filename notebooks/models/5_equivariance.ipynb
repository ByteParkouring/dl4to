{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10debb76-06b2-485c-9d47-f813e2e79062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c4d12-7f58-4be9-801d-812df3f29cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torch\n",
    "import random\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa3c0c-5ec8-4453-ab55-f99b1f996889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf28bb5-329f-4b35-a724-fbf2a4b188fc",
   "metadata": {},
   "source": [
    "# Equivariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb784fb6-49c1-4027-853a-514e6ea25601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EquivarianceWrapper:\n",
    "    \"\"\"\n",
    "    A class that represents an equivariance wrapper [1] that implements group equivariance via group averaging [2].\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 preprocessing:\"dl4to.preprocessing.Preprocessing\"=None, # The preprocessing strategy to use. This is used in the equivariance wrapper to obtain the scalar and vector field information of the input.\n",
    "                 rotate:bool=True, # Whether to include rotational equivariance in the transformation group.\n",
    "                 mirror:bool=True, # Whether to include mirror equivariance in the transformation group.\n",
    "                 dim:int=2, # The dimension of the transformation group. Specifically, a 2d transformation group does not consider rotations and mirrors along the z-axis.\n",
    "                 rotate_twice:bool=False, # Whether double-rotations should be used, where the input is rotated twice, along two different axes. This may result in a larger transformation group.\n",
    "                 sample_rate:float=1. # The rate of transformations that should be randomly sampled in the forward pass. `sample_rate=1.` defaults to all transformations being used in the wrapper. A smaller choice may be beneficial if memory constraints don't allow for the applications of all transformations in each forward pass.\n",
    "                ):\n",
    "        self.preprocessing = preprocessing\n",
    "        assert dim == 2 or dim == 3\n",
    "        self.rotate = rotate\n",
    "        self.mirror = mirror\n",
    "        self.dim = dim\n",
    "        self.sample_rate = sample_rate\n",
    "        self.cube_face_indices = self._get_cube_face_indices()\n",
    "        self.rotate_twice = rotate_twice\n",
    "        self.name = self._get_name()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def preprocessing(self):\n",
    "        return self._preprocessing\n",
    "\n",
    "\n",
    "    @preprocessing.setter\n",
    "    def preprocessing(self, preprocessing):\n",
    "        self._preprocessing = preprocessing\n",
    "        if preprocessing is not None:\n",
    "            vector_directions = preprocessing.vector_directions\n",
    "            self.vector_field_channels = self._get_vector_field_channels(vector_directions)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_name(self):\n",
    "        name = \"equiv\"\n",
    "        if self.rotate:\n",
    "            name += \"_rot\"\n",
    "        if self.mirror:\n",
    "            name += \"_mir\"\n",
    "        if self.rotate_twice:\n",
    "            name += \"_twice\"\n",
    "        name += f\"_{self.dim}d\"\n",
    "        return name\n",
    "\n",
    "\n",
    "    def _get_cube_face_indices(self):\n",
    "        cube_face_indices = [0, 1, 3, 4]\n",
    "        if self.dim == 3:\n",
    "            cube_face_indices.extend([2, 5])\n",
    "        return cube_face_indices\n",
    "\n",
    "\n",
    "    def _get_vector_field_channels(self, vector_directions):\n",
    "        x_channel_idx = [i for i, vector_direction in enumerate(vector_directions) if vector_direction == 'x']\n",
    "        y_channel_idx = [i for i, vector_direction in enumerate(vector_directions) if vector_direction == 'y']\n",
    "        z_channel_idx = [i for i, vector_direction in enumerate(vector_directions) if vector_direction == 'z']\n",
    "        return [x_channel_idx, y_channel_idx, z_channel_idx]\n",
    "\n",
    "\n",
    "    def mirror_input(self, \n",
    "                     x:torch.Tensor, # The input that should be mirrored/flipped.\n",
    "                     flip_dimensions:list # The dimension along which the input should be mirrored.\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        Returnes a `torch.Tensor`, which is a mirrored version of the input `x`.\n",
    "        \"\"\"\n",
    "        x = torch.flip(x, flip_dimensions)\n",
    "        x = self._mirror_vector_fields(x, flip_dimensions)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _mirror_vector_fields(self, x, flip_dimensions):\n",
    "        for flip_dimension in flip_dimensions:\n",
    "            for flip_channel in self.vector_field_channels[flip_dimension]:\n",
    "                x[:,flip_channel] = -x[:,flip_channel]\n",
    "        return x\n",
    "\n",
    "\n",
    "    def rotate_input(self, \n",
    "                     x:torch.Tensor, # The input that should be rotated.\n",
    "                     rotations:int, # The number of 90Â° rations that should be performed. Four rotations result in the identity.\n",
    "                     plane:list # On which plane the input should be rotated.\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        Returnes a `torch.Tensor`, which is a rotated version of the input `x`.\n",
    "        \"\"\"\n",
    "        x = torch.rot90(x, rotations, plane)\n",
    "        x = self._rotate_vector_fields(x, rotations, plane)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _rotate_vector_fields(self, x, rotations, plane):\n",
    "        assert plane[0] < 0 and plane[1] < 0, \"Indices of rotational plane must be given in negative integers\"\n",
    "        assert len(x.shape) == 5\n",
    "        force_index_0, force_index_1 = self.vector_field_channels[plane[0]], self.vector_field_channels[plane[1]]\n",
    "\n",
    "        if rotations % 4 == 1:\n",
    "            temp = x[:,force_index_0].clone()\n",
    "            x[:,force_index_0] = -x[:,force_index_1]\n",
    "            x[:,force_index_1] = temp\n",
    "\n",
    "        if rotations % 4 == 2:\n",
    "            x[:,force_index_0] = -x[:,force_index_0]\n",
    "            x[:,force_index_1] = -x[:,force_index_1]\n",
    "\n",
    "        if rotations % 4 == 3:\n",
    "            temp = x[:,force_index_0].clone()\n",
    "            x[:,force_index_0] = x[:,force_index_1]\n",
    "            x[:,force_index_1] = -temp\n",
    "        return x\n",
    "\n",
    "\n",
    "    def __get_rotations_and_plane_for_first_rotation(self, cube_face_index):\n",
    "        if cube_face_index == 0: rotations, plane =  0, [-3, -2]\n",
    "        if cube_face_index == 1: rotations, plane =  1, [-3, -2]\n",
    "        if cube_face_index == 2: rotations, plane = -1, [-1, -3]\n",
    "        if cube_face_index == 3: rotations, plane =  2, [-3, -2]\n",
    "        if cube_face_index == 4: rotations, plane =  3, [-3, -2]\n",
    "        if cube_face_index == 5: rotations, plane =  1, [-1, -3]\n",
    "        return rotations, plane\n",
    "\n",
    "\n",
    "    def __get_rotations_and_plane_for_second_rotation(self, cube_face_index):\n",
    "        rotations = [0,2]\n",
    "        if cube_face_index%3 == 0: plane = [-2, -1]\n",
    "        if cube_face_index%3 == 1: plane = [-1, -3]\n",
    "        if self.dim == 3:\n",
    "            rotations.extend([1, 3])\n",
    "            if cube_face_index%3 == 2: plane = [-3, -2]\n",
    "        return rotations, plane\n",
    "\n",
    "\n",
    "    def _get_rotations(self):\n",
    "        transforms = []\n",
    "        for cube_face_index in self.cube_face_indices:\n",
    "            rotations, plane = self.__get_rotations_and_plane_for_first_rotation(cube_face_index)\n",
    "            face_transform = lambda x, rotations=rotations, plane=plane: self.rotate_input(x, rotations, plane)\n",
    "            inverse_face_transform = lambda x, rotations=rotations, plane=plane: torch.rot90(x, -rotations, plane)\n",
    "\n",
    "            if self.rotate_twice:\n",
    "                rotations, plane = self.__get_rotations_and_plane_for_second_rotation(cube_face_index)\n",
    "                for rotation in rotations:\n",
    "                    transform = lambda x, face_transform=face_transform, rotation=rotation, plane=plane: self.rotate_input(face_transform(x), rotation, plane)\n",
    "                    inverse_transform = lambda x, inverse_face_transform=inverse_face_transform, rotation=rotation, plane=plane: inverse_face_transform(torch.rot90(x, -rotation, plane))\n",
    "                    transforms.append((transform, inverse_transform))\n",
    "            else:\n",
    "                transforms.append((face_transform, inverse_face_transform))\n",
    "        return transforms\n",
    "\n",
    "\n",
    "    def _get_flip_dimensions(self, rotation_transforms):\n",
    "        flip_dimensions = []\n",
    "\n",
    "        if len(rotation_transforms) != 1:\n",
    "            bool_combinations = [[True]]\n",
    "        else:\n",
    "            bool_combinations = [[True, False] for _ in range(self.dim)]\n",
    "\n",
    "        for axes in product(*bool_combinations):\n",
    "            flip_dimension = []\n",
    "\n",
    "            for i, axis in enumerate(axes):\n",
    "                if axis:\n",
    "                    flip_dimension.append(-3+i)\n",
    "\n",
    "            flip_dimensions.append(flip_dimension)\n",
    "        return flip_dimensions\n",
    "\n",
    "\n",
    "    def _get_mirrors(self, rotation_transforms):\n",
    "        transforms = []\n",
    "        flip_dimensions = self._get_flip_dimensions(rotation_transforms)\n",
    "\n",
    "        for rotation_transform, inverse_rotation_transform in rotation_transforms:\n",
    "            for flip_dimension in flip_dimensions:\n",
    "                transform = lambda x, rotation_transform=rotation_transform, flip_dimension=flip_dimension: rotation_transform(self.mirror_input(x, flip_dimension))\n",
    "                inverse_transform = lambda x, inverse_rotation_transform=inverse_rotation_transform, flip_dimension=flip_dimension: torch.flip(inverse_rotation_transform(x), flip_dimension)\n",
    "                transforms.append((transform, inverse_transform))\n",
    "        return transforms\n",
    "\n",
    "\n",
    "    def _sample_transforms(self, transforms, sample_rate):\n",
    "        if sample_rate == 1.:\n",
    "            return transforms\n",
    "        number_of_sampled_transforms = max(1, round(len(transforms) * sample_rate))\n",
    "        sampled_transforms = random.sample(transforms, k=number_of_sampled_transforms)\n",
    "        return sampled_transforms\n",
    "\n",
    "\n",
    "    def get_transforms(self,\n",
    "                       sample_rate:float=None # The rate of transformations that should be randomly samples from the equivariance wrapper. `None` defaults to `equivariance_wrapper.sample_rate`. `1.` means that all transformations are considered.\n",
    "                      ):\n",
    "        \"\"\"\n",
    "        Returns a list of all group actions that are applied to an input in the equivariance wrapper.\n",
    "        \"\"\"\n",
    "        if sample_rate is None:\n",
    "            sample_rate = self.sample_rate\n",
    "        rotation_transforms = [(lambda x: x, lambda x: x)]\n",
    "        transforms = []\n",
    "        if self.rotate:\n",
    "            rotation_transforms = self._get_rotations()\n",
    "            transforms = rotation_transforms\n",
    "        if self.mirror:\n",
    "            transforms += self._get_mirrors(rotation_transforms)\n",
    "        transforms = self._sample_transforms(transforms, sample_rate)\n",
    "        return transforms\n",
    "\n",
    "\n",
    "    def __call__(self, \n",
    "                 model:torch.nn.Module # The model that should be turned into an equivariant model.\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Applies the equivariance wrapper to a `torch.nn.Module` model object and returns an `dl4to.models.EquivariantModel` object.\n",
    "        \"\"\"\n",
    "        assert self.vector_field_channels is not None, print(\"EquivarianceWrapper does not have a preprocessing.\")\n",
    "        return EquivariantModel(model=model, equivariance_wrapper=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953228d9-0f7b-47ad-84ca-9a3993bc8116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EquivarianceWrapper.mirror_input\" class=\"doc_header\"><code>EquivarianceWrapper.mirror_input</code><a href=\"__main__.py#L65\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EquivarianceWrapper.mirror_input</code>(**`x`**:`Tensor`, **`flip_dimensions`**:`list`)\n",
       "\n",
       "Returnes a `torch.Tensor`, which is a mirrored version of the input `x`.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`x`**|`Tensor`||The input that should be mirrored/flipped.|\n",
       "|**`flip_dimensions`**|`list`||The dimension along which the input should be mirrored.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EquivarianceWrapper.mirror_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05639196-333a-4c2c-a7f7-c2b97487fb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EquivarianceWrapper.rotate_input\" class=\"doc_header\"><code>EquivarianceWrapper.rotate_input</code><a href=\"__main__.py#L84\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EquivarianceWrapper.rotate_input</code>(**`x`**:`Tensor`, **`rotations`**:`int`, **`plane`**:`list`)\n",
       "\n",
       "Returnes a `torch.Tensor`, which is a rotated version of the input `x`.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`x`**|`Tensor`||The input that should be rotated.|\n",
       "|**`rotations`**|`int`||The number of 90Â° rations that should be performed. Four rotations result in the identity.|\n",
       "|**`plane`**|`list`||On which plane the input should be rotated.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EquivarianceWrapper.rotate_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c9c2c-0d54-4766-b524-ec80d3760b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EquivarianceWrapper.get_transforms\" class=\"doc_header\"><code>EquivarianceWrapper.get_transforms</code><a href=\"__main__.py#L195\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EquivarianceWrapper.get_transforms</code>(**`sample_rate`**:`float`=*`None`*)\n",
       "\n",
       "Returns a list of all group actions that are applied to an input in the equivariance wrapper.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`sample_rate`**|`float`|`None`|The rate of transformations that should be randomly samples from the equivariance wrapper. `None` defaults to `equivariance_wrapper.sample_rate`. `1.` means that all transformations are considered.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EquivarianceWrapper.get_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e2390-73fe-4e0a-9bdd-55f907197209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EquivarianceWrapper.__call__\" class=\"doc_header\"><code>EquivarianceWrapper.__call__</code><a href=\"__main__.py#L214\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EquivarianceWrapper.__call__</code>(**`model`**:`Module`)\n",
       "\n",
       "Applies the equivariance wrapper to a `torch.nn.Module` model object and returns an `dl4to.models.EquivariantModel` object.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`model`**|`Module`||The model that should be turned into an equivariant model.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EquivarianceWrapper.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ee2ef-49f8-40cf-85a4-41d1831eb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EquivariantModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A class that represents an equivariant model with respect to a specific equivariance wrapper.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model:torch.nn.Module, # A PyTorch neural network.\n",
    "                 equivariance_wrapper:\"dl4to.models.EquivarianceWrapper\" # The equivariance wrapper that is applied to the model.\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.equivariance_wrapper = equivariance_wrapper\n",
    "\n",
    "\n",
    "    def __call__(self, \n",
    "                 model_inputs:torch.Tensor, # The model inputs that are obtained as output of the preprocessing.\n",
    "                 sample_rate:float=None # The rate of transformations that should be randomly samples from the equivariance wrapper. `None` defaults to `equivariance_wrapper.sample_rate`.`1.` means that all transformations are applied in the forward pass.\n",
    "                ):\n",
    "        \"\"\"\n",
    "        The forward method for the equivariant model.\n",
    "        \"\"\"\n",
    "        assert model_inputs.shape[1] == len(self.equivariance_wrapper.preprocessing.vector_directions)\n",
    "        transforms = self.equivariance_wrapper.get_transforms(sample_rate)\n",
    "        model_outputs = 0\n",
    "        for transform, inverse_transform in transforms:\n",
    "            model_inputs_transformed = transform(model_inputs)\n",
    "            model_outputs_transformed = self.model(model_inputs_transformed)\n",
    "            model_outputs += inverse_transform(model_outputs_transformed)\n",
    "        return model_outputs / len(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670ef26-9824-43e2-9e0d-546a77b92ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EquivariantModel.__call__\" class=\"doc_header\"><code>EquivariantModel.__call__</code><a href=\"__main__.py#L15\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EquivariantModel.__call__</code>(**`model_inputs`**:`Tensor`, **`sample_rate`**:`float`=*`None`*)\n",
       "\n",
       "The forward method for the equivariant model.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`model_inputs`**|`Tensor`||The model inputs that are obtained as output of the preprocessing.|\n",
       "|**`sample_rate`**|`float`|`None`|The rate of transformations that should be randomly samples from the equivariance wrapper. `None` defaults to `equivariance_wrapper.sample_rate`.`1.` means that all transformations are applied in the forward pass.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EquivariantModel.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce79b13-4176-4f8f-ba93-d41da614e65b",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068fed4-efe4-4c64-a87e-6281f24b7263",
   "metadata": {},
   "source": [
    "[1] Dittmer, SÃ¶ren, et al. \"SELTO: Sample-Efficient Learned Topology Optimization.\" arXiv preprint arXiv:2209.05098 (2022).\n",
    "\n",
    "[2] Puny, Omri, et al. \"Frame averaging for invariant and equivariant network design.\" arXiv preprint arXiv:2110.03336 (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e70dcca-9c6a-41c6-a00c-c8b2a59b6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from dl4to.preprocessing import ForcePreprocessing, TrivialPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b59c818-4db6-4d8c-a4b7-37848a8d84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.55 s, sys: 0 ns, total: 4.55 s\n",
      "Wall time: 254 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "#slow\n",
    "\n",
    "def test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate, mirror, dim, rotate_twice, verbose=False):\n",
    "    shape = [20, 20, 20]\n",
    "    p0 = [0., 0., 0.]\n",
    "    p1 = [.1 , .1 , .1]\n",
    "\n",
    "    inputs = torch.zeros(2, 3, *shape)\n",
    "    inputs[0, :, :20, :1] = 1.\n",
    "    inputs[1, :, :20, :1] = .6\n",
    "\n",
    "\n",
    "    preprocessing = ForcePreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing,\n",
    "                                       rotate=rotate, mirror=mirror, \n",
    "                                       dim=dim, rotate_twice=rotate_twice)\n",
    "    sampled_transforms = equivariance.get_transforms(sample_rate=1)\n",
    "\n",
    "    for i, (transform, inverse_transform) in enumerate(sampled_transforms):\n",
    "        inputs_transformed = transform(inputs)\n",
    "        negatives_in_sample_zero = True\n",
    "        negatives_in_sample_one = True\n",
    "\n",
    "        if not torch.allclose(inputs, inputs_transformed) and not (rotate and mirror):\n",
    "            if (rotate and dim == 3) and (i == 6 or i == 19):\n",
    "                pass\n",
    "            else:\n",
    "                negatives_in_sample_zero = torch.any(inputs_transformed[0] < 0)\n",
    "                negatives_in_sample_one = torch.any(inputs_transformed[1] < 0)\n",
    "\n",
    "        inputs_aggregated_and_transformed = inputs_transformed.abs().sum(dim=1)\n",
    "        prediction = inverse_transform(inputs_aggregated_and_transformed)\n",
    "\n",
    "        target = inputs.abs().sum(dim=1)\n",
    "\n",
    "        target_and_prediction_are_the_same = torch.allclose(target, prediction)\n",
    "\n",
    "        assert negatives_in_sample_zero, f\"no negatives in sample 0 for transform {i}.\"\n",
    "        assert negatives_in_sample_one, f\"no negatives in sample 1 for transform {i}.\"\n",
    "        assert target_and_prediction_are_the_same, f\"target and prediction are different for transform {i}.\"\n",
    "\n",
    "\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=True, mirror=False, dim=2, rotate_twice=False)\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=False, mirror=True, dim=2, rotate_twice=False)\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=True, mirror=True, dim=2, rotate_twice=False)\n",
    "\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=True, mirror=False, dim=2, rotate_twice=True)\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=False, mirror=True, dim=2, rotate_twice=True)\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=True, mirror=True, dim=2, rotate_twice=True)\n",
    "\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=True, mirror=False, dim=3, rotate_twice=True)\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=False, mirror=True, dim=3, rotate_twice=True)\n",
    "test_that_transform_aggregation_and_inverse_transform_yields_the_aggregated_input_for_batch_size_larger_one(rotate=True, mirror=True, dim=3, rotate_twice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-johnson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 Âµs, sys: 0 ns, total: 215 Âµs\n",
      "Wall time: 218 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate, mirror, dim, rotate_twice):\n",
    "    preprocessing = ForcePreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing, \n",
    "                                       rotate=rotate, mirror=mirror,\n",
    "                                       dim=dim, rotate_twice=rotate_twice)\n",
    "    n_transforms = 0\n",
    "    if dim == 2:\n",
    "        if rotate:\n",
    "            n_transforms += 4\n",
    "            if rotate_twice:\n",
    "                n_transforms += 4\n",
    "        if mirror:\n",
    "            n_transforms += 4\n",
    "            if rotate_twice and rotate:\n",
    "                n_transforms += 4\n",
    "        assert len(equivariance.get_transforms(sample_rate=1)) == n_transforms, (len(equivariance.get_transforms(sample_rate=1)), n_transforms)\n",
    "\n",
    "    if dim == 3:\n",
    "        if rotate:\n",
    "            n_transforms += 24\n",
    "        if mirror:\n",
    "            n_transforms += 8\n",
    "        if rotate and mirror:\n",
    "            n_transforms += 16\n",
    "        assert len(equivariance.get_transforms(sample_rate=1)) == n_transforms, (len(equivariance.get_transforms(sample_rate=1)), n_transforms)\n",
    "\n",
    "\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=True, mirror=False, dim=2, rotate_twice=False)\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=False, mirror=True, dim=2, rotate_twice=False)\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=True, mirror=True, dim=2, rotate_twice=False)\n",
    "\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=True, mirror=False, dim=2, rotate_twice=True)\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=False, mirror=True, dim=2, rotate_twice=True)\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=True, mirror=True, dim=2, rotate_twice=True)\n",
    "\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=True, mirror=False, dim=3, rotate_twice=True)\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=False, mirror=True, dim=3, rotate_twice=True)\n",
    "test_that_transformation_groups_yield_the_correct_number_of_transforms(rotate=True, mirror=True, dim=3, rotate_twice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 ms, sys: 0 ns, total: 25 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_transformation_group_yields_unique_transformations(rotate, mirror, dim, rotate_twice):\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing, \n",
    "                                       rotate=rotate, mirror=mirror,\n",
    "                                       dim=dim, rotate_twice=rotate_twice)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "    list_of_transformed_tensors = []\n",
    "\n",
    "    for transformation, _ in equivariance.get_transforms(sample_rate=1):\n",
    "        x_ = transformation(x)\n",
    "        for transformed_tensor in list_of_transformed_tensors:\n",
    "            assert not torch.equal(x_, transformed_tensor)\n",
    "        list_of_transformed_tensors.append(x_)\n",
    "\n",
    "\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=True, mirror=False, dim=2, rotate_twice=False)\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=False, mirror=True, dim=2, rotate_twice=False)\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=True, mirror=True, dim=2, rotate_twice=False)\n",
    "\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=True, mirror=False, dim=2, rotate_twice=True)\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=False, mirror=True, dim=2, rotate_twice=True)\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=True, mirror=True, dim=2, rotate_twice=True)\n",
    "\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=True, mirror=False, dim=3, rotate_twice=True)\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=False, mirror=True, dim=3, rotate_twice=True)\n",
    "test_that_transformation_group_yields_unique_transformations(rotate=True, mirror=True, dim=3, rotate_twice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 ms, sys: 0 ns, total: 27 ms\n",
      "Wall time: 25.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_transformation_group_yields_uniquely_sampled_transformations(rotate, mirror, dim, rotate_twice):\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing, \n",
    "                                       rotate=rotate, mirror=mirror,\n",
    "                                       dim=dim, rotate_twice=rotate_twice)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    list_of_transformed_tensors = []\n",
    "\n",
    "    for transformation, _ in equivariance.get_transforms(sample_rate=1):\n",
    "        x_ = transformation(x)\n",
    "        for transformed_tensor in list_of_transformed_tensors:\n",
    "            assert not torch.equal(x_, transformed_tensor)\n",
    "        list_of_transformed_tensors.append(x_)\n",
    "\n",
    "\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=True, mirror=False, dim=2, rotate_twice=False)\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=False, mirror=True, dim=2, rotate_twice=False)\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=True, mirror=True, dim=2, rotate_twice=False)\n",
    "\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=True, mirror=False, dim=2, rotate_twice=True)\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=False, mirror=True, dim=2, rotate_twice=True)\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=True, mirror=True, dim=2, rotate_twice=True)\n",
    "\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=True, mirror=False, dim=3, rotate_twice=True)\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=False, mirror=True, dim=3, rotate_twice=True)\n",
    "test_that_transformation_group_yields_uniquely_sampled_transformations(rotate=True, mirror=True, dim=3, rotate_twice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-store",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 ms, sys: 293 Âµs, total: 4.37 ms\n",
      "Wall time: 3.65 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_rotate_vector_fields_changes_the_tensor():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    planes = [[-2, -1], [-1, -3], [-3, -2]]\n",
    "    rotations = [-3, -2, -1, 1, 2, 3]\n",
    "    for plane in planes:\n",
    "        for rotation in rotations:\n",
    "            x_original = x.clone()\n",
    "            assert not torch.allclose(x_original, equivariance._rotate_vector_fields(x, rotation, plane))\n",
    "\n",
    "\n",
    "test_that_rotate_vector_fields_changes_the_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.66 ms, sys: 0 ns, total: 2.66 ms\n",
      "Wall time: 2.41 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_rotate_vector_fields_is_invertable():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    planes = [[-2, -1], [-1, -3], [-3, -2]]\n",
    "    rotations = [0, 1, 2, 3]\n",
    "\n",
    "    for plane in planes:\n",
    "        for rotation in rotations:\n",
    "            x_original = x.clone()\n",
    "            assert torch.allclose(x_original, equivariance._rotate_vector_fields(equivariance._rotate_vector_fields(x, rotation, plane), -rotation, plane))\n",
    "\n",
    "\n",
    "test_that_rotate_vector_fields_is_invertable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.28 ms, sys: 0 ns, total: 6.28 ms\n",
      "Wall time: 5.76 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_rotate_vector_fields_works_correctly():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    planes = [[-2, -1], [-1, -3], [-3, -2]]\n",
    "    rotations = [-3, -2, -1, 1, 2, 3]\n",
    "\n",
    "    for plane in planes:\n",
    "        for rotation in rotations:\n",
    "            x_original = x.clone()\n",
    "            assert not torch.allclose(x_original, equivariance._rotate_vector_fields(x, rotation, plane))\n",
    "\n",
    "\n",
    "test_that_rotate_vector_fields_works_correctly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-graduation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.47 ms, sys: 29 Âµs, total: 8.5 ms\n",
      "Wall time: 7.65 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_rotate_changes_the_tensor():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    planes = [[-2, -1], [-1, -3], [-3, -2]]\n",
    "    rotations = [-3, -2, -1, 1, 2, 3]\n",
    "\n",
    "    for plane in planes:\n",
    "        for rotation in rotations:\n",
    "            x_original = x.clone()\n",
    "            assert not torch.allclose(x_original, equivariance.rotate_input(x, rotation, plane))\n",
    "\n",
    "\n",
    "test_that_rotate_changes_the_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-baker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.71 ms, sys: 59 Âµs, total: 5.77 ms\n",
      "Wall time: 4.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_rotate_is_invertable():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    planes = [[-2, -1], [-1, -3], [-3, -2]]\n",
    "    rotations = [0, 1, 2, 3]\n",
    "\n",
    "    for plane in planes:\n",
    "        for rotation in rotations:\n",
    "            x_original = x.clone()\n",
    "            assert torch.allclose(x_original, equivariance.rotate_input(equivariance.rotate_input(x, rotation, plane), -rotation, plane))\n",
    "\n",
    "\n",
    "test_that_rotate_is_invertable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-failing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 ms, sys: 0 ns, total: 1.47 ms\n",
      "Wall time: 1.31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that__mirror_vector_fields_changes_the_tensor():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    for flip_x_axis in [False, True]:\n",
    "        for flip_y_axis in [False, True]:\n",
    "            for flip_z_axis in [False, True]:\n",
    "                flip_dimensions = []\n",
    "                if flip_x_axis: flip_dimensions.append(-3)\n",
    "                if flip_y_axis: flip_dimensions.append(-2)\n",
    "                if flip_z_axis: flip_dimensions.append(-1)\n",
    "\n",
    "                if any([flip_x_axis, flip_y_axis, flip_z_axis]):\n",
    "                    x_original = x.clone()\n",
    "                    assert not torch.allclose(x_original, equivariance._mirror_vector_fields(x, flip_dimensions))\n",
    "\n",
    "\n",
    "test_that__mirror_vector_fields_changes_the_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.73 ms, total: 1.73 ms\n",
      "Wall time: 1.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_mirror_changes_the_tensor():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    for flip_x_axis in [False, True]:\n",
    "        for flip_y_axis in [False, True]:\n",
    "            for flip_z_axis in [False, True]:\n",
    "                flip_dimensions = []\n",
    "                if flip_x_axis:\n",
    "                    flip_dimensions.append(-3)\n",
    "                if flip_y_axis:\n",
    "                    flip_dimensions.append(-2)\n",
    "                if flip_z_axis:\n",
    "                    flip_dimensions.append(-1)\n",
    "\n",
    "                if any([flip_x_axis, flip_y_axis, flip_z_axis]):\n",
    "                    x_original = x.clone()\n",
    "                    assert not torch.allclose(x_original, equivariance.mirror_input(x, flip_dimensions=flip_dimensions))\n",
    "\n",
    "\n",
    "test_that_mirror_changes_the_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.97 ms, sys: 0 ns, total: 1.97 ms\n",
      "Wall time: 1.73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that__mirror_vector_fields_is_invertable():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    for flip_x_axis in [False, True]:\n",
    "        for flip_y_axis in [False, True]:\n",
    "            for flip_z_axis in [False, True]:\n",
    "                flip_dimensions = []\n",
    "                if flip_x_axis: flip_dimensions.append(-3)\n",
    "                if flip_y_axis: flip_dimensions.append(-2)\n",
    "                if flip_z_axis: flip_dimensions.append(-1)\n",
    "\n",
    "                if any([flip_x_axis, flip_y_axis, flip_z_axis]):\n",
    "                    x_original = x.clone()\n",
    "                    assert torch.allclose(x_original, equivariance._mirror_vector_fields(equivariance._mirror_vector_fields(x, flip_dimensions), flip_dimensions))\n",
    "\n",
    "\n",
    "test_that__mirror_vector_fields_is_invertable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 ms, sys: 0 ns, total: 2.3 ms\n",
      "Wall time: 2.07 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#hide\n",
    "\n",
    "def test_that_mirror_is_invertable():\n",
    "    preprocessing = TrivialPreprocessing()\n",
    "    equivariance = EquivarianceWrapper(preprocessing=preprocessing)\n",
    "    x = torch.rand(10, 7, 3, 3, 3)\n",
    "\n",
    "    for flip_x_axis in [False, True]:\n",
    "        for flip_y_axis in [False, True]:\n",
    "            for flip_z_axis in [False, True]:\n",
    "                flip_dimensions = []\n",
    "                if flip_x_axis: flip_dimensions.append(-3)\n",
    "                if flip_y_axis: flip_dimensions.append(-2)\n",
    "                if flip_z_axis: flip_dimensions.append(-1)\n",
    "\n",
    "                if any([flip_x_axis, flip_y_axis, flip_z_axis]):\n",
    "                    x_original = x.clone()\n",
    "                    assert torch.allclose(x_original, equivariance.mirror_input(equivariance.mirror_input(x, flip_dimensions), flip_dimensions))\n",
    "\n",
    "\n",
    "test_that_mirror_is_invertable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
