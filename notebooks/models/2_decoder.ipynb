{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fbf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from dl4to.models import ConvolutionalBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc7666-18bb-4385-ab9f-794e4d80d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1064c9f-21ec-40e4-807d-f97442067153",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5809251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DecodingBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines a decoding block for the decoder.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_skip_connection:int, # The number of input channels from the skip connections of the encoder.\n",
    "        dimensions:int, # The number of dimensions to consider. Possible options are 2 and 3.\n",
    "        upsampling_type:str, # The type of upsampling to use.\n",
    "        normalization:str, # The type of normalization to use. Possible options include \"batch\", \"layer\" and \"instance\".\n",
    "        preactivation:bool, # Whether to use preactivations.\n",
    "        residual:bool=False, # Whether the decoder should be a residual network.\n",
    "        use_padding:bool=False, # Whether to use padding.\n",
    "        padding_mode:str='zeros', # The type of padding to use.\n",
    "        activation:str='ReLU', # The activation function that should be used.\n",
    "        dilation:int=None, # The amount of dilation that should be used.\n",
    "        dropout:float=0., # The dropout rate.\n",
    "        upsample_recover_orig_size:bool=False, # Whether the original input size of the encoder should be recovered with the decoder output.\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = residual\n",
    "        self.upsampling_type = upsampling_type\n",
    "        self.upsample_recover_orig_size = upsample_recover_orig_size\n",
    "\n",
    "        if upsampling_type == 'conv':\n",
    "            if upsample_recover_orig_size:\n",
    "                print(\"Ignoring upsample_recover_orig_size=False when using upsampling_type=conv.\")\n",
    "\n",
    "            in_channels = out_channels = 2 * in_channels_skip_connection\n",
    "            self.upsample = self._get_conv_transpose_layer(dimensions, in_channels, out_channels)\n",
    "        else:\n",
    "            self.upsample = self._get_upsampling_layer(upsampling_type)\n",
    "\n",
    "        in_channels_first = 3 * in_channels_skip_connection\n",
    "        out_channels = in_channels_skip_connection\n",
    "\n",
    "        self.conv1 = ConvolutionalBlock(\n",
    "            dimensions=dimensions,\n",
    "            in_channels=in_channels_first,\n",
    "            out_channels=out_channels,\n",
    "            normalization=normalization,\n",
    "            preactivation=preactivation,\n",
    "            use_padding=use_padding,\n",
    "            padding_mode=padding_mode,\n",
    "            activation=activation,\n",
    "            dilation=dilation,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        in_channels_second = out_channels\n",
    "\n",
    "        self.conv2 = ConvolutionalBlock(\n",
    "            dimensions=dimensions,\n",
    "            in_channels=in_channels_second,\n",
    "            out_channels=out_channels,\n",
    "            normalization=normalization,\n",
    "            preactivation=preactivation,\n",
    "            use_padding=use_padding,\n",
    "            padding_mode=padding_mode,\n",
    "            activation=activation,\n",
    "            dilation=dilation,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        if residual:\n",
    "            self.conv_residual = ConvolutionalBlock(\n",
    "                dimensions=dimensions,\n",
    "                in_channels=in_channels_first,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                normalization=None,\n",
    "                activation=None\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                skip_connection:list, # A list of `torch.Tensors` that contain the outputs of the skip connections from an encoding block.\n",
    "                x:torch.Tensor # The input to the decoding block.\n",
    "               ):\n",
    "        \"\"\"\n",
    "        The forward pass of the decoding block.\n",
    "        \"\"\"\n",
    "        if self.upsampling_type != 'conv':\n",
    "            if self.upsample_recover_orig_size:\n",
    "                self.upsample.size = skip_connection.shape[-3:]\n",
    "            else:\n",
    "                self.upsample.scale_factor = 2.\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        skip_connection = self._center_crop(skip_connection, x)\n",
    "        x = torch.cat((skip_connection, x), dim=1)\n",
    "\n",
    "        if self.residual:\n",
    "            connection = self.conv_residual(x)\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x += connection\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _get_upsampling_layer(self, upsampling_type):\n",
    "        upsampling_modes = ('nearest', 'linear', 'bilinear', 'bicubic', 'trilinear')\n",
    "\n",
    "        if upsampling_type not in upsampling_modes:\n",
    "            message = (f'Upsampling type is {upsampling_type} but should be one of the following: {upsampling_modes}.')\n",
    "            raise ValueError(message)\n",
    "\n",
    "        upsample = nn.Upsample(mode=upsampling_type)\n",
    "        return upsample\n",
    "\n",
    "\n",
    "    def _get_conv_transpose_layer(self, dimensions, in_channels, out_channels):\n",
    "        conv_class = getattr(nn, f'ConvTranspose{dimensions}d')\n",
    "        conv_layer = conv_class(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        return conv_layer\n",
    "\n",
    "\n",
    "    def _center_crop(self, skip_connection, x):\n",
    "        skip_shape = np.array(skip_connection.shape)\n",
    "        x_shape = np.array(x.shape)\n",
    "\n",
    "        crop = skip_shape[2:] - x_shape[2:]\n",
    "        half_crop = torch.tensor(crop // 2)\n",
    "\n",
    "        pad = -torch.stack((half_crop, half_crop)).t().flatten()\n",
    "\n",
    "        skip_connection = F.pad(skip_connection, pad.tolist())\n",
    "        return skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f10fa2-d60a-493e-90e7-7f7f56095be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DecodingBlock.forward\" class=\"doc_header\"><code>DecodingBlock.forward</code><a href=\"__main__.py#L79\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DecodingBlock.forward</code>(**`skip_connections`**:`list`, **`x`**:`Tensor`)\n",
       "\n",
       "The forward pass of the decoding block.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`skip_connections`**|`list`||A list of `torch.Tensors` that contain the outputs of the skip connections from an encoding block.|\n",
       "|**`x`**|`Tensor`||The input to the decoding block.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DecodingBlock.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a decoder that can be used for the construction of UNets [1].\n",
    "    The decoder is a neural network that takes the feature vector from the encoder and decodes it into an output.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_skip_connection:int, # The number of input channels from the skip connections of the encoder.\n",
    "        dimensions:int, # The number of dimensions to consider. Possible options are 2 and 3.\n",
    "        upsampling_type:str, # The type of upsampling to use.\n",
    "        num_decoding_blocks:int, # The number of decoding blocks.\n",
    "        normalization:str, # The type of normalization to use. Possible options include \"batch\", \"layer\" and \"instance\".\n",
    "        preactivation:bool, # Whether to use preactivations.\n",
    "        residual:bool=False, # Whether the decoder should be a residual network.\n",
    "        use_padding:bool=False, # Whether to use padding.\n",
    "        padding_mode:str='zeros', # The type of padding to use.\n",
    "        activation:str='ReLU', # The activation function that should be used.\n",
    "        initial_dilation:int=None, # The amount of dilation that should be used in the first encoding block.\n",
    "        dropout:float=0., # The dropout rate.\n",
    "        upsample_recover_orig_size:bool=False, # Whether the original input size of the encoder should be recovered with the decoder output.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        upsampling_type = self._fix_upsampling_type(upsampling_type, dimensions)\n",
    "\n",
    "        self.decoding_blocks = nn.ModuleList()\n",
    "        self.dilation = initial_dilation\n",
    "\n",
    "        for _ in range(num_decoding_blocks):\n",
    "            decoding_block = DecodingBlock(\n",
    "                in_channels_skip_connection=in_channels_skip_connection,\n",
    "                dimensions=dimensions,\n",
    "                upsampling_type=upsampling_type,\n",
    "                normalization=normalization,\n",
    "                preactivation=preactivation,\n",
    "                residual=residual,\n",
    "                use_padding=use_padding,\n",
    "                padding_mode=padding_mode,\n",
    "                activation=activation,\n",
    "                dilation=self.dilation,\n",
    "                dropout=dropout,\n",
    "                upsample_recover_orig_size=upsample_recover_orig_size\n",
    "            )\n",
    "\n",
    "            self.decoding_blocks.append(decoding_block)\n",
    "            in_channels_skip_connection = in_channels_skip_connection // 2\n",
    "\n",
    "            if self.dilation is not None:\n",
    "                self.dilation = self.dilation // 2\n",
    "\n",
    "\n",
    "    def _fix_upsampling_type(self, upsampling_type, dimensions):\n",
    "        if upsampling_type == 'linear':\n",
    "            if dimensions == 2:\n",
    "                upsampling_type = 'bilinear'\n",
    "            elif dimensions == 3:\n",
    "                upsampling_type = 'trilinear'\n",
    "\n",
    "        return upsampling_type\n",
    "\n",
    "\n",
    "    def forward(self, \n",
    "                skip_connections:list, # A list of `torch.Tensors` that contain the outputs of the skip connections from an encoder.\n",
    "                x:torch.Tensor # The input to the decoder.\n",
    "               ):\n",
    "        \"\"\"\n",
    "        The forward pass of the decoder.\n",
    "        \"\"\"\n",
    "        zipped = zip(reversed(skip_connections), self.decoding_blocks)\n",
    "\n",
    "        for skip_connection, decoding_block in zipped:\n",
    "            x = decoding_block(skip_connection, x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195f720-9ce7-473e-82fb-209dfad2f730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Decoder.forward\" class=\"doc_header\"><code>Decoder.forward</code><a href=\"__main__.py#L62\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Decoder.forward</code>(**`skip_connections`**:`list`, **`x`**:`Tensor`)\n",
       "\n",
       "The forward pass of the decoder.\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`skip_connections`**|`list`||A list of `torch.Tensors` that contain the outputs of the skip connections from an encoder.|\n",
       "|**`x`**|`Tensor`||The input to the decoder.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Decoder.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e41aae-9da3-462a-867b-7fe19e1cca01",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6decaecd-0231-43c4-8e54-fd4d1c50c598",
   "metadata": {},
   "source": [
    "[1] Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
