# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/criteria/2_unsupervised_criteria.ipynb (unless otherwise specified).

__all__ = ['Criterion', 'WeightedCriterion', 'CombinedCriterion', 'SupervisedCriterion', 'WeightedBCE', 'WeightedFocal',
           'Dice', 'Tversky', 'FocalTversky', 'IoU', 'VoxelAccuracy', 'BalancedVoxelAccuracy', 'L2Accuracy',
           'UnsupervisedCriterion', 'Compliance', 'Volume', 'VolumeFraction', 'VolumeConstraint', 'ForcesUnderpinned',
           'MaxStress', 'StressConstraint', 'Fail', 'StressEfficiency', 'Binariness']

# Cell
import torch

# Cell
class Criterion():
    """
    A parent class that inherits all criteria for both classical and learned methods. Criteria can be used as objective or loss functions, as well as evaluation metrics.
    """
    def __init__(
        self,
        name:str, # The name of this criterion which will be monitored in logging.
        supervised:bool, # Whether the criterion is supervised or not.
        differentiable:bool=True, # Whether the criterion is differentiable or not. Only differentiable criteria can be used as loss/objective functions.
        lower_is_better:bool=True, # Whether lower values of the criterion correspond to better scores.
        compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
    ):
        self._name = name
        self._supervised = supervised
        self._differentiable = differentiable
        self._lower_is_better = lower_is_better
        self.compute_only_on_design_space = compute_only_on_design_space


    @property
    def name(self):
        return self._name


    @property
    def supervised(self):
        return self._supervised


    @property
    def differentiable(self):
        return self._differentiable


    @property
    def lower_is_better(self):
        return self._lower_is_better


    def get_θ_flat(self,
                   solutions:list, # A list of solutions from which the densities are extracted and flattened into one output tensor.
                   binary:bool=False # Whether the densities should be binarized.
                  ):
        """
        Returns a flattened density distribution tensor from the passed solutions.
        """
        θ = torch.stack([solution.get_θ(binary=binary).flatten() for solution in solutions])
        θ.clamp_(0,1)
        return θ


    def get_design_space_mask(self,
                              solutions:list # A list of solutions from which the design space mask is extracted and combined into a single output tensor.
                             ):
        """
        Returns a flattened design space mask from the passed solutions. If `compute_only_on_design_space=False`, then a ones-vector is returned.
        """
        device = solutions[0].get_θ().device
        if self.compute_only_on_design_space:
            return torch.stack([solution.problem.Ω_design.flatten() == -1 for solution in solutions]).to(device)
        else:
            shape_flat = torch.numel(solutions[0].get_θ())
            return torch.ones(len(solutions), shape_flat, dtype=torch.bool).to(device)


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Only used if `Criterion.supervised=True`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions. The gt_solutions are only used if `self.criterion.supervised=True`.
        """
        raise NotImplementedError("Must be overridden.")


    def __add__(self,
                criterion:"dl4to.criteria.Criterion" # A second criterion that should be combined with the current one.
               ):
        """
        The summation of two criteria results in a new combined criterion. Returns a `dl4to.criteria.CombinedCriterion` object.
        """
        combined_criterion = CombinedCriterion(self, criterion)
        return combined_criterion


    def __rmul__(self,
                 λ:float # The multiplier which the criterion is weighted with.
                ):
        """
        The multiplication of a criterion with a scalar results in a weighted criterion. Returns a `dl4to.criteria.WeightedCriterion` object.
        """
        return WeightedCriterion(self, λ)


    def __mul__(self,
                 λ:float # The multiplier which the criterion is weighted with.
                ):
        """
        The multiplication of a criterion with a scalar results in a weighted criterion. Returns a `dl4to.criteria.WeightedCriterion` object.
        """
        return self.__rmul__(λ)

# Cell
class WeightedCriterion(Criterion):
    """
    A class that represents a criterion that has a weight factor in front of it. This is especially useful for constrained optimization or regularization.
    Note that the unweighted criterion can be accessed via `self.criterion`.
    """
    def __init__(self,
                 criterion:"dl4to.criteria.Criterion", # The criterion object that is being weighted.
                 λ:float # The weighting factor for the criterion.
                ):
        self.criterion = criterion
        self.λ = λ
        lower_is_better = (not self.criterion.lower_is_better) if self.λ < 0 else (self.criterion.lower_is_better)

        super().__init__(
            name=f'{self.λ}_{self.criterion.name}',
            supervised=self.criterion.supervised,
            differentiable=self.criterion.differentiable,
            lower_is_better=lower_is_better,
            compute_only_on_design_space=self.criterion.compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Only used if `Criterion.supervised=True`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions. The gt_solutions are only used if `self.criterion.supervised=True`.
        """
        return self.λ * self.criterion(solutions, gt_solutions, binary)

# Cell
class CombinedCriterion(Criterion):
    """
    A class that represents the combination of two criteria by a plus sign "+" between them. Both individual criteria can be accessed via `self.criterion1` and `self.criterion2`.
    """
    def __init__(self,
                 criterion1:"dl4to.criteria.Criterion", # The first criterion of the summation.
                 criterion2:"dl4to.criteria.Criterion" # The second criterion of the summation.
                ):
        self.criterion1 = criterion1
        self.criterion2 = criterion2
        name = f"{self.criterion1.name}_plus_{self.criterion2.name}"
        supervised=self.criterion1.supervised or self.criterion2.supervised
        differentiable = self.criterion1.differentiable and self.criterion2.differentiable
        if self.criterion1.lower_is_better != self.criterion2.lower_is_better:
            raise AttributeError("Cannot combine two criteria with different values in `lower_is_better`.")
        lower_is_better = self.criterion1.lower_is_better
        compute_only_on_design_space = self.criterion1.compute_only_on_design_space and self.criterion2.compute_only_on_design_space
        super().__init__(
            name=name,
            supervised=supervised,
            differentiable=differentiable,
            lower_is_better=lower_is_better,
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Only used if `Criterion.supervised=True`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions. The gt_solutions are only used if `self.criterion.supervised=True`.
        """
        criterion1_vals = self.criterion1(solutions, gt_solutions, binary)
        criterion2_vals = self.criterion2(solutions, gt_solutions, binary)
        if criterion1_vals.device != criterion2_vals.device:
            if criterion1_vals.device == torch.device('cpu'):
                criterion1_vals = criterion1_vals.to(criterion2_vals.device)
            if criterion2_vals.device == torch.device('cpu'):
                criterion2_vals = criterion2_vals.to(criterion1_vals.device)
        return criterion1_vals + criterion2_vals

# Cell
import torch
import numpy as np
from torch.nn.functional import mse_loss, binary_cross_entropy

from .criteria import Criterion

# Cell
class SupervisedCriterion(Criterion):
    """
    A parent class that inherits all supervised criteria for both classical and learned methods.
    """
    def __init__(
        self,
        name:str, # The name of this criterion which will be monitored in logging.
        differentiable:bool=True, # Whether the criterion is differentiable or not. Only differentiable criteria can be used as loss/objective functions.
        lower_is_better:bool=True, # Whether lower values of the criterion correspond to better scores.
        compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
    ):
        super().__init__(name=name,
                         supervised=True,
                         differentiable=differentiable,
                         lower_is_better=lower_is_better,
                         compute_only_on_design_space=compute_only_on_design_space
                        )


    def _convert_to_list(self, solutions, gt_solutions):
        if type(solutions) is tuple:
            solutions = list(solutions)
        if type(gt_solutions) is tuple:
            gt_solutions = list(gt_solutions)
        if type(solutions) is not list:
            solutions = [solutions]
        if type(gt_solutions) is not list:
            gt_solutions = [gt_solutions]
        return solutions, gt_solutions


    def _check_inputs(self, solutions, gt_solutions):
        if gt_solutions is None:
            raise AttributeError('The criterion is supervised and needs ground thruth data. Therefore, gt_solution should not be None.')

        for gt_solution in gt_solutions:
            if gt_solution is None:
                raise ValueError('The criterion requires gt_solutions, which are currently None.')


    def _get_number_of_true_positives(self, θ, θ_true, design_space_mask):
        return (θ_true * θ * design_space_mask).sum(dim=1)


    def _get_number_of_true_negatives(self, θ, θ_true, design_space_mask):
        return ((1 - θ_true) * (1 - θ) * design_space_mask).sum(dim=1)


    def _get_number_of_false_positives(self, θ, θ_true, design_space_mask):
        return ((1 - θ_true) * θ * design_space_mask).sum(dim=1)


    def _get_number_of_false_negatives(self, θ, θ_true, design_space_mask):
        return (θ_true * (1 - θ) * design_space_mask).sum(dim=1)


    def _get_sensitivity(self, θ, θ_true, design_space_mask, ε=1e-6): # same as recall
        tp = self._get_number_of_true_positives(θ, θ_true, design_space_mask)
        fn = self._get_number_of_false_negatives(θ, θ_true, design_space_mask)
        return tp / (tp + fn + ε)


    def _get_specificity(self, θ, θ_true, design_space_mask, ε=1e-6):
        tn = self._get_number_of_true_negatives(θ, θ_true, design_space_mask)
        fp = self._get_number_of_false_positives(θ, θ_true, design_space_mask)
        return tn / (tn + fp + ε)


    def _get_precision(self, θ, θ_true, design_space_mask, ε=1e-6):
        tp = self._get_number_of_true_positives(θ, θ_true, design_space_mask)
        fp = self._get_number_of_false_positives(θ, θ_true, design_space_mask)
        return tp / (tp + fp + ε)


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        raise NotImplementedError("Must be overridden.")

# Cell
class WeightedBCE(SupervisedCriterion):
    """
    Weighted Binary cross entropy [1] is a variant of binary cross entropy variant. The weight value can be used to tune false negatives and false positives.
    E.g; If you want to reduce the number of false negatives then set weight > 1, similarly to decrease the number of false positives, set weight < 1.
    The criterion reaches its best value at 0 and higher values correspond to worse scores.
    """
    def __init__(self,
                 weight:float=.5, # The weight of the weighted binary cross entropy function which is used to take class imbalance into account.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.weight = weight
        super().__init__(
            name=f'BCE({weight:.2})',
            compute_only_on_design_space=compute_only_on_design_space
        )


    def set_optimal_weight(self,
                           dataset:"dl4to.dataset.TopoDataset", # The dataset based on which the optimal weight is determined.
                           binary:bool=False # Whether the densities in the solutions are thresholded at 0.5 before the weight is determined.
                          ):
        """
        Calculates the optimal BCE weight based on the solutions in the dataset.
        """
        gt_solutions = dataset.get_gt_solutions()
        θ = torch.stack([gt_solution.get_θ(binary=binary).flatten() for gt_solution in gt_solutions])
        design_space_mask = self.get_design_space_mask(gt_solutions)
        self.weight = 1. - θ.sum() / design_space_mask.sum()
        print(f"Setting criterion weight to {self.weight}.")
        self._name = f'BCE({self.weight:.2})'


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)
        loss = binary_cross_entropy(
            θ * design_space_mask, θ_true * design_space_mask,
            weight=torch.tensor([self.weight], device=θ.device),
            reduction='none'
        )

        return loss.sum(dim=1) / design_space_mask.sum(dim=1)

# Cell
class WeightedFocal(SupervisedCriterion):
    """
    Focal loss [2] can be seen as variation of Binary Cross-Entropy. It down-weights the contribution of easy examples and enables the model to focus more on learning hard examples.
    It works well for highly imbalanced class scenarios. The criterion reaches its best value at 0 and higher values correspond to worse scores.
    """
    def __init__(self,
                 weight:float=.5, # The weight of the weighted focal function which is used to take class imbalance into account.
                 γ:float=3, # $γ\geq0$ is the tunable focusing parameter. Setting $γ>0$ reduces the relative loss for well-classified examples, putting more focus on hard, misclassified examples.
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.weight = weight
        self.γ = γ
        self.ε = ε
        super().__init__(
            name=f'Focal({weight:.2})',
            compute_only_on_design_space=compute_only_on_design_space
        )


    def set_optimal_weight(self,
                           dataset:"dl4to.dataset.TopoDataset", # The dataset based on which the optimal weight is determined.
                           binary:bool=False # Whether the densities in the solutions are thresholded at 0.5 before the weight is determined.
                          ):
        """
        Calculates the optimal BCE weight based on the solutions in the dataset.
        """
        gt_solutions = dataset.get_gt_solutions()
        θ = torch.stack([gt_solution.get_θ(binary=binary).flatten() for gt_solution in gt_solutions])
        design_space_mask = self.get_design_space_mask(gt_solutions)
        self.weight = 1. - θ.sum() / design_space_mask.sum()
        print(f"Setting criterion weight to {self.weight}.")
        self._name = f'BCE({self.weight:.2})'


    def _get_loss(self, θ, θ_true, design_space_mask):
        bce_loss = binary_cross_entropy(θ * design_space_mask, θ_true * design_space_mask, reduction='none')
        pt = torch.clamp(torch.exp(- bce_loss * design_space_mask), min=self.ε, max=1-self.ε)
        loss = self.weight * (1 - pt)**self.γ * bce_loss

        return loss.sum(dim=1) / design_space_mask.sum(dim=1)


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)

        return self._get_loss(θ, θ_true, design_space_mask)

# Cell
class Dice(SupervisedCriterion):
    """
    The Dice coefficient is widely used metric in computer vision community to calculate the similarity between two images.
    Later in 2016, it has also been adapted as loss function known as Dice Loss [3]. It is also sometimes refered to as the F1 score [4].
    Dice reaches its best value at 0 and its worst value at 1.
    """
    def __init__(self,
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.ε = ε
        super().__init__(
            name='Dice',
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)

        tp = self._get_number_of_true_positives(θ, θ_true, design_space_mask)
        fp = self._get_number_of_false_positives(θ, θ_true, design_space_mask)
        fn = self._get_number_of_false_negatives(θ, θ_true, design_space_mask)
        dice_score = 2.*tp / (2.*tp + fp + fn + self.ε)

        return 1 - dice_score

# Cell
class Tversky(SupervisedCriterion):
    """
    Tversky index [5] can be seen as a generalization of the Dice coefficient. It adds a weight to false positives and false negatives. By setting the value of α > 0.5, we can penalise false negatives more.
    This becomes useful in highly imbalanced datasets where the additional level of control over the loss function yields better small scale segmentations than the normal dice coefficient.
    Just like dice, this criterion reaches its best value at 0 and its worst value at 1.
   """
    def __init__(self,
                 α:float=.5, # The Tversky weight. When $α=0.5$, it can be solved into the regular Dice coefficient.
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.α = α
        self.β = 1 - α
        self.ε = ε
        super().__init__(
            name=f'Tversky({α})',
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)

        tp = self._get_number_of_true_positives(θ, θ_true, design_space_mask)
        fp = self._get_number_of_false_positives(θ, θ_true, design_space_mask)
        fn = self._get_number_of_false_negatives(θ, θ_true, design_space_mask)
        tversky = tp / (tp + self.α * fn + self.β * fp + self.ε)

        return 1 - tversky

# Cell
class FocalTversky(SupervisedCriterion):
    """
    The Focal Tversky Loss [6] is a generalisation of the Tversky loss. The non-linear nature of the loss gives control over how the loss behaves at different values of the Tversky index obtained.
    Similar to Focal Loss, which focuses on hard examples by down-weighting easy ones. Focal Tversky loss  also attempts to learn hard-examples such with the help of γ, which controls the non-linearity of the loss.
    This criterion reaches its best value at 0, while higher values correspond to worse scores.
    """
    def __init__(self,
                 α:float=.5, # The Tversky weight. When $α=0.5$, it can be solved into the regular Dice coefficient.
                 γ:float=3, # $γ\geq0$ is the Focal loss focusing parameter. Setting $γ>0$ reduces the relative loss for well-classified examples, putting more focus on hard, misclassified examples.
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.α = α
        self.β = 1 - α
        self.γ = γ
        self.ε = ε
        super().__init__(
            name=f'focal_Tversky({α})',
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)

        tp = self._get_number_of_true_positives(θ, θ_true, design_space_mask)
        fp = self._get_number_of_false_positives(θ, θ_true, design_space_mask)
        fn = self._get_number_of_false_negatives(θ, θ_true, design_space_mask)
        tversky = tp / (tp + self.α * fn + self.β * fp + self.ε)

        return (1 - tversky)**self.γ

# Cell
class IoU(SupervisedCriterion):
    """
    The Intersection over Union (IoU) metric, also referred to as the Jaccard index, is essentially a method to quantify the percent overlap between the target mask and our prediction output. This metric is closely related to the Dice coefficient which is often used as a loss function during training.
    The IoU metric measures the number of pixels common between the target and prediction masks divided by the total number of pixels present across both masks.
    IoU reaches its best value at 1 and its worst value at 0, i.e., higher values are better.
   """
    def __init__(self,
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.ε = ε
        super().__init__(
            name='IoU',
            lower_is_better=False,
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)

        tp = self._get_number_of_true_positives(θ, θ_true, design_space_mask)
        fp = self._get_number_of_false_positives(θ, θ_true, design_space_mask)
        fn = self._get_number_of_false_negatives(θ, θ_true, design_space_mask)

        return tp / (tp + fn + fp + self.ε)

# Cell
class VoxelAccuracy(SupervisedCriterion):
    """
    The voxel accuracy loss is a three-dimensional version of the pixel accuracy loss [7]. It reports the percent of voxels which are correctly classified. This metric can sometimes provide misleading results when the class representation is small within the image, as the measure will be biased in mainly reporting how well you identify negative case (ie. where the class is not present).
    Voxel accuracy reaches its best value at 1 and its worst value at 0, i.e., higher values are better.
    """
    def __init__(self,
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.ε = ε
        super().__init__(
            name='voxel_accuracy',
            lower_is_better=False,
            compute_only_on_design_space=compute_only_on_design_space)


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)

        tp = self._get_number_of_true_positives(θ, θ_true, design_space_mask)
        tn = self._get_number_of_true_negatives(θ, θ_true, design_space_mask)
        fp = self._get_number_of_false_positives(θ, θ_true, design_space_mask)
        fn = self._get_number_of_false_negatives(θ, θ_true, design_space_mask)

        return (tp + tn) / (tp + tn + fp + fn + self.ε)

# Cell
class BalancedVoxelAccuracy(SupervisedCriterion):
    """
    The balanced voxel accuracy loss [9] is a balanced version of the voxel accuracy criterion and can also be interpreted as a rescaled version of the "Youden index" [10]. That makes it a better metric to use with imbalanced data. It is defined as the average of recall obtained on each class.
    The criterion reaches its best value at 1 and its worst value at 0, i.e., higher values are better.
    """
    def __init__(self,
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.ε = ε
        super().__init__(
            name=f'balanced_voxel_accuracy',
            lower_is_better=False,
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)
        sensitivity = self._get_sensitivity(θ, θ_true, design_space_mask, ε=self.ε)
        specificity = self._get_specificity(θ, θ_true, design_space_mask, ε=self.ε)
        return (sensitivity + specificity) / 2.

# Cell
class L2Accuracy(SupervisedCriterion):
    """
    The L2 accuracy loss [8] reports the root mean squared accuracy of the predictions. The criterion reaches its best value at 1 and its worst value at 0, i.e., higher values are better.
    """
    def __init__(self,
                 ε:float=1e-6, # A small value $>0$ that avoids division by $0$ and therefore improves numerical stability.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.ε = ε
        super().__init__(
            name='L2_accuracy',
            lower_is_better=False,
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions, gt_solutions = self._convert_to_list(solutions, gt_solutions)
        self._check_inputs(solutions, gt_solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        θ_true = self.get_θ_flat(gt_solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)
        loss = mse_loss(θ * design_space_mask, θ_true * design_space_mask, reduction='none')
        return 1 - torch.sqrt(loss.sum(dim=1) / design_space_mask.sum(dim=1) + self.ε)

# Cell
import warnings
import torch
import numpy as np
from torch.nn.functional import relu, softplus

from .utils import infect
from .criteria import Criterion

# Cell
class UnsupervisedCriterion(Criterion):
    """
    A parent class that inherits all unsupervised criteria for both classical and learned methods.
    """
    def __init__(
        self,
        name:str, # The name of this criterion which will be monitored in logging.
        differentiable:bool=True, # Whether the criterion is differentiable or not. Only differentiable criteria can be used as loss/objective functions.
        lower_is_better:bool=True, # Whether lower values of the criterion correspond to better scores.
        compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
    ):
        super().__init__(name=name,
                         supervised=False,
                         differentiable=differentiable,
                         lower_is_better=lower_is_better,
                         compute_only_on_design_space=compute_only_on_design_space
                        )


    def _convert_to_list(self, solutions):
        if type(solutions) is tuple:
            solutions = list(solutions)
        if type(solutions) is not list:
            solutions = [solutions]
        return solutions


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        raise NotImplementedError("Must be overridden.")

# Cell
class Compliance(UnsupervisedCriterion):
    """
    The compliance criterion which is used to determine the structural integrity of mechanical structures.
    The criterionis computes as $F^T u$, where $F$ are the external forces and $u$ are the displacements, which are derived from the PDE for linear elasticity.
    Lower values are desired and higher values indicate worse scores.
    """
    def __init__(self,
                 α:float=1e-9 # The weight that is used to rescale the forces F.
                ):
        self.α = α
        super().__init__(
            name=f'compliance',
            compute_only_on_design_space=False
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        compliance_list = []
        for i, solution in enumerate(solutions):
            u, σ, σ_vm = solution.solve_pde(binary=binary)
            F = self.α * solution.problem.F.flatten()
            compliance_list.append(torch.dot(F, u.flatten().float()))
        return torch.stack(compliance_list)

# Cell
class Volume(UnsupervisedCriterion):
    """
    Calculates the sum over all density values for each solution.
    """
    def __init__(self,
                 compute_only_on_design_space:bool=False # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        super().__init__(
            name=f'volume',
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        θ = self.get_θ_flat(solutions, binary=binary)
        design_space_mask = self.get_design_space_mask(solutions)
        θ_design = θ * design_space_mask
        return θ_design.sum(dim=1)

# Cell
class VolumeFraction(UnsupervisedCriterion):
    """
    Calculates the average density values for each solution. Therefore this criterion always returns values between 0 and 1.
    """
    def __init__(self,
                 compute_only_on_design_space:bool=False # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        super().__init__(
            name=f'volume_fraction',
            compute_only_on_design_space=compute_only_on_design_space
        )
        self.volume_crit = Volume()


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        volume = self.volume_crit(solutions, gt_solutions, binary)
        design_space_mask = self.get_design_space_mask(solutions)
        return volume / design_space_mask.sum(dim=1)

# Cell
class VolumeConstraint(UnsupervisedCriterion):
    """
    This criterion checks if the volume fraction is below a pre-defined maximum volume fraction and punishes higher volumes.
    """
    def __init__(self,
                 max_volume_fraction:float=0.2, # The maximum volume fraction threshold given as a float between 0 and 1.
                 threshold_fct:str='softplus', # The function that determines how volume values above `max_volume_fraction` are punished. Can be either "relu" or "softplus", which is a smoothed version of ReLU.
                 compute_only_on_design_space:bool=False # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        super().__init__(
                name=f'volume_constraint',
                compute_only_on_design_space=compute_only_on_design_space
            )
        self.max_volume_fraction = max_volume_fraction
        if threshold_fct == 'softplus':
            self.threshold_fct = softplus
        elif threshold_fct == 'relu':
            self.threshold_fct = relu
        else:
            raise ValueError("`threshold_fct` must be one of ['softplus', 'relu'].")
        self.volume_fraction_crit = VolumeFraction(
            compute_only_on_design_space=compute_only_on_design_space
        )


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        volume_fraction = self.volume_fraction_crit(solutions, gt_solutions, binary)
        positives_are_too_large = volume_fraction - self.max_volume_fraction
        approximately_only_positives = self.threshold_fct(positives_are_too_large)
        return approximately_only_positives

# Cell
class ForcesUnderpinned(UnsupervisedCriterion):
    """
    This criterion uses an infection algorithm to check if all voxels that have external forces applied to them are connected to the rest of the structure.
    Returns 1 if the structure is connected, else it returns 0.
    """
    def __init__(self):
        super().__init__(
            name=f'forces_underpinned',
            lower_is_better=False,
            compute_only_on_design_space=False)


    def _one_channel_are_forces_underpinned(self, forces, dirichlet, density):
        assert dirichlet.dtype == density.dtype, f"{dirichlet.dtype} != {density.dtype}"
        assert dirichlet.device == density.device, f"{dirichlet.device} != {density.device}"

        underpinned = infect(dirichlet, density)
        underpinned_forces = underpinned & forces
        return torch.all(underpinned_forces == forces).item()


    def _are_forces_underpinned(self, F, Ω_dirichlet, θ):
        underpinned = True
        for i in range(3):
            if not self._one_channel_are_forces_underpinned(F[i], Ω_dirichlet[i], θ[0]):
                underpinned = False
        return underpinned


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        results = []
        if binary == False:
            warnings.warn("Automatically setting binary=True for ForcesUnderpinned Criterion.")
            binary = True
        for solution in solutions:
            θ = solution.get_θ(binary=binary) == 1
            F = solution.problem.F != 0
            Ω_dirichlet = solution.problem.Ω_dirichlet

            F = F.type(θ.dtype).to(θ.device)
            Ω_dirichlet = Ω_dirichlet.type(θ.dtype).to(θ.device)

            underpinned = self._are_forces_underpinned(F, Ω_dirichlet, θ)
            results.append(underpinned)

        return torch.tensor(results, dtype=torch.float32, device=θ.device)

# Cell
class MaxStress(UnsupervisedCriterion):
    """
    This criterion solves the PDE for linear elasticity and returns the maximum absolute von Mises stress value for each passed solution. If `normalize=True` then the value is normalized with the yield stress of the problem.
    """
    def __init__(self,
                 compute_only_for_not_underpinned:bool=True, # Whether not connected voxels should be included in the calculation. If True, then the maximum stress is only computed for voxels that are connected to the structure.
                 normalize:bool=True # Whether the maximal absolute von Mises stress should be normalized with the yield stress.
                ):
        super().__init__(
            name=f'max_stress',
            compute_only_on_design_space=False
        )
        self.compute_only_for_not_underpinned = compute_only_for_not_underpinned
        self.normalize = normalize
        if self.compute_only_for_not_underpinned:
            self.forces_underpinned_crit = ForcesUnderpinned()


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        if self.compute_only_for_not_underpinned:
            forces_underpinned = self.forces_underpinned_crit(solutions, gt_solutions, binary)
        else:
            forces_underpinned = len(solutions) * [1.]

        σ_vm_list = []
        σ_ys_list = []
        for i, solution in enumerate(solutions):
            if forces_underpinned[i] == 1:
                u, σ, σ_vm = solution.solve_pde(binary=binary)
                σ_vm_list.append(σ_vm.flatten())
                if self.normalize:
                    σ_ys_list.append(solution.problem.σ_ys)

        if σ_vm_list == [] and self.normalize:
            return torch.tensor([0.])

        σ_vm_ = torch.stack(σ_vm_list)
        if self.normalize:
            σ_ys_ = torch.tensor(σ_ys_list, device=σ_vm_.device)
            return σ_vm_.amax(dim=1) / σ_ys_
        return σ_vm_.amax(dim=1)

# Cell
class StressConstraint(UnsupervisedCriterion):
    """
    This criterion solves the PDE for linear elasticity and checks if the absolute maximum von Mises stress is below the yield stress and punishes higher stress values.
    """
    def __init__(self,
                 threshold_fct:str='softplus' # The function that determines how von Mises stress values above the yield stress are punished. Can be either "relu" or "softplus", which is a smoothed version of ReLU.
                ):
        super().__init__(
                name=f'stress_constraint',
                compute_only_on_design_space=False
            )
        if threshold_fct == 'softplus':
            self.threshold_fct = softplus
        elif threshold_fct == 'relu':
            self.threshold_fct = relu
        else:
            raise ValueError("`threshold_fct` must be one of ['softplus', 'relu'].")


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        positives_are_too_large = []
        for i, solution in enumerate(solutions):
            u,  σ, σ_vm = solution.solve_pde(binary=binary)
            positives_are_too_large.append(σ_vm - solution.problem.σ_ys)
        positives_are_too_large = torch.stack(positives_are_too_large)
        approximately_only_positives = self.threshold_fct(positives_are_too_large)
        return (approximately_only_positives ** 2).mean(dim=[1,2,3,4]) / 2

# Cell
class Fail(UnsupervisedCriterion):
    """
    Checks for each solution if the structure fails to either underpinned force (i.e., the forces are not connected to the rest of the structure) or too high von Mises stresses.
    If the structure fails for any of these reasons, then the criterion returns a value of 1, otherwise it returns 0.
    Averaging over the output of this criterion results in the fail percentage criterion [1].
    """
    def __init__(self,
                 ε:float=.1 # A tolerance that defines how much the absolute maximal von Mises stresses are tolerated to be slightly higher than the yield stresses. By default, this value is 0.1, i.e., a structure does still count as valid if the von Mises stresses are below 110% of the yield stress.
                ):
        super().__init__(
            name=f'fail',
            compute_only_on_design_space=False
        )
        self.ε = ε
        self.max_stress_crit = MaxStress(compute_only_for_not_underpinned=True, normalize=True)
        self.forces_underpinned_crit = ForcesUnderpinned()


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        failed_due_to_max_stress = (self.max_stress_crit(solutions, gt_solutions, binary=binary) > 1 + self.ε).float()
        failed_total = (~self.forces_underpinned_crit(solutions, gt_solutions, binary=True).bool()).float()
        failed_total.cpu()[failed_total == 0.] = failed_due_to_max_stress

        return failed_total

# Cell
class StressEfficiency(UnsupervisedCriterion):
    """
    Returns the stress efficiency, which is calculated by dividing the mean von Mises stress through the maximum absolute von Mises stress.
    """
    def __init__(self,
                 compute_only_for_not_underpinned:bool=True # Whether not connected voxels should be included in the calculation. If True, then the stress efficiency is only computed for voxels that are connected to the structure.
                ):
        super().__init__(
            name=f'stress_efficiency',
            lower_is_better=False,
            compute_only_on_design_space=False
        )
        self.compute_only_for_not_underpinned = compute_only_for_not_underpinned
        if self.compute_only_for_not_underpinned:
            self.forces_underpinned_crit = ForcesUnderpinned()


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        if self.compute_only_for_not_underpinned:
            forces_underpinned = self.forces_underpinned_crit(solutions, gt_solutions, binary)
        else:
            forces_underpinned = len(solutions) * [1.]

        σ_vm_list = []
        for i, solution in enumerate(solutions):
            if forces_underpinned[i] == 1:
                u, σ, σ_vm = solution.solve_pde(binary=binary)
                σ_vm_list.append(σ_vm.flatten())

        if σ_vm_list == []:
            return torch.tensor([0.])

        σ_vm_ = torch.stack(σ_vm_list)
        return σ_vm_.mean(dim=1) / σ_vm_.amax(dim=1)

# Cell
class Binariness(UnsupervisedCriterion):
    """
    This criterion is a measure for how binary a density distribution is. A value of 1 indicates that all density values are below `low` or above `high`. A value of 0 indicates that all values are between `low` and `high`.
    """
    def __init__(self,
                 low:bool=.1, # The lower threshold below which densities are considered binary.
                 high:bool=.9, # The upper threshold above which densities are considered binary.
                 compute_only_on_design_space:bool=True # Whether the criterion should be evaluated on voxels that have a design space information of -1, i.e., the voxels can be freely optimized. This parameter does not effect all criteria.
                ):
        self.low = low
        self.high = high
        super().__init__(
            name=f'binariness',
            compute_only_on_design_space=compute_only_on_design_space)


    def __call__(self,
                 solutions:list, # The solutions that should be evaluated with the criterion.
                 gt_solutions:list=None, # Ground truth solutions that are compared element-wise with the `solutions`. Since the criterion is unsupervised this does not have an effect.
                 binary:bool=False # Whether the criterion should be evaluated on binarized densities. Does not have an effect on some criteria.
                  ):
        """
        Calculates the output of the criterion for all solutions.
        """
        solutions = self._convert_to_list(solutions)
        θ = self.get_θ_flat(solutions, binary=False)
        design_space_mask = self.get_design_space_mask(solutions)
        θ_design = θ * design_space_mask
        θ_design_filtered = torch.where(
            ((θ_design < self.low) & design_space_mask) | (θ_design > self.high),
            torch.tensor([1.], device=θ.device),
            torch.tensor([0.], device=θ.device)
        )
        return θ_design_filtered.sum(dim=1) / design_space_mask.sum(dim=1)