---

title: Encoder


keywords: fastai
sidebar: home_sidebar



nb_path: "notebooks/models/1_encoder.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/models/1_encoder.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EncodingBlock" class="doc_header"><code>class</code> <code>EncodingBlock</code><a href="dl4to/models.py#L140" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EncodingBlock</code>(<strong><code>in_channels</code></strong>:<code>int</code>, <strong><code>out_channels_first</code></strong>:<code>int</code>, <strong><code>dimensions</code></strong>:<code>int</code>, <strong><code>normalization</code></strong>:<code>str</code>, <strong><code>pooling_type</code></strong>:<code>str</code>, <strong><code>pooling_kernel_size</code></strong>:<code>int</code>, <strong><code>preactivation</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>is_first_block</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>residual</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>use_padding</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>padding_mode</code></strong>:<code>str</code>=<em><code>'zeros'</code></em>, <strong><code>activation</code></strong>:<code>str</code>=<em><code>'ReLU'</code></em>, <strong><code>dilation</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>dropout</code></strong>:<code>float</code>=<em><code>0.0</code></em>) :: <code>Module</code></p>
</blockquote>
<p>This class defines a single encoding block for an encoder.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>in_channels</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of input channels.</td>
</tr>
<tr>
<td><strong><code>out_channels_first</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of output channels after the first encoding step.</td>
</tr>
<tr>
<td><strong><code>dimensions</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of dimensions to consider. Possible options are 2 and 3.</td>
</tr>
<tr>
<td><strong><code>normalization</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of normalization to use. Possible options include "batch", "layer" and "instance".</td>
</tr>
<tr>
<td><strong><code>pooling_type</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of pooling to use.</td>
</tr>
<tr>
<td><strong><code>pooling_kernel_size</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The size of the pooling kernel.</td>
</tr>
<tr>
<td><strong><code>preactivation</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to use preactivations.</td>
</tr>
<tr>
<td><strong><code>is_first_block</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether this is the first block of an encoder.</td>
</tr>
<tr>
<td><strong><code>residual</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether the encoder should be a residual network.</td>
</tr>
<tr>
<td><strong><code>use_padding</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to use padding.</td>
</tr>
<tr>
<td><strong><code>padding_mode</code></strong></td>
<td><code>str</code></td>
<td><code>zeros</code></td>
<td>The type of padding to use.</td>
</tr>
<tr>
<td><strong><code>activation</code></strong></td>
<td><code>str</code></td>
<td><code>ReLU</code></td>
<td>The activation function that should be used.</td>
</tr>
<tr>
<td><strong><code>dilation</code></strong></td>
<td><code>int</code></td>
<td><code>None</code></td>
<td>The amount of dilation that should be used.</td>
</tr>
<tr>
<td><strong><code>dropout</code></strong></td>
<td><code>float</code></td>
<td><code>0.0</code></td>
<td>The dropout rate.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EncodingBlock.forward" class="doc_header"><code>EncodingBlock.forward</code><a href="dl4to/models.py#L218" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EncodingBlock.forward</code>(<strong><code>x</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>The forward pass of the encoding block.
Returns a list of <code>torch.Tensors</code> that define the outputs of the skip connections, and a <code>torch.Tensor</code> that is the output of the encoding block.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>x</code></strong></td>
<td><code>Tensor</code></td>
<td></td>
<td>the input to the encoding block.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Encoder" class="doc_header"><code>class</code> <code>Encoder</code><a href="dl4to/models.py#L256" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Encoder</code>(<strong><code>in_channels</code></strong>:<code>int</code>, <strong><code>out_channels_first</code></strong>:<code>int</code>, <strong><code>dimensions</code></strong>:<code>int</code>, <strong><code>pooling_type</code></strong>:<code>str</code>, <strong><code>num_encoding_blocks</code></strong>:<code>int</code>, <strong><code>normalization</code></strong>:<code>str</code>, <strong><code>pooling_kernel_size</code></strong>:<code>int</code>, <strong><code>preactivation</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>residual</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>use_padding</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>padding_mode</code></strong>:<code>str</code>=<em><code>'zeros'</code></em>, <strong><code>activation</code></strong>:<code>str</code>=<em><code>'ReLU'</code></em>, <strong><code>initial_dilation</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>dropout</code></strong>:<code>float</code>=<em><code>0.0</code></em>) :: <code>Module</code></p>
</blockquote>
<p>This class defines an encoder that can be used for the construction of UNets [1].
An encoder is a neural network that takes the input, and outputs a feature vector for each input sample.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>in_channels</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of input channels.</td>
</tr>
<tr>
<td><strong><code>out_channels_first</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of output channels after the first encoding step.</td>
</tr>
<tr>
<td><strong><code>dimensions</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of dimensions to consider. Possible options are 2 and 3.</td>
</tr>
<tr>
<td><strong><code>pooling_type</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of pooling to use.</td>
</tr>
<tr>
<td><strong><code>num_encoding_blocks</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of encoding blocks.</td>
</tr>
<tr>
<td><strong><code>normalization</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of normalization to use. Possible options include "batch", "layer" and "instance".</td>
</tr>
<tr>
<td><strong><code>pooling_kernel_size</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The size of the pooling kernel.</td>
</tr>
<tr>
<td><strong><code>preactivation</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to use preactivations.</td>
</tr>
<tr>
<td><strong><code>residual</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether the encoder should be a residual network.</td>
</tr>
<tr>
<td><strong><code>use_padding</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to use padding.</td>
</tr>
<tr>
<td><strong><code>padding_mode</code></strong></td>
<td><code>str</code></td>
<td><code>zeros</code></td>
<td>The type of padding to use.</td>
</tr>
<tr>
<td><strong><code>activation</code></strong></td>
<td><code>str</code></td>
<td><code>ReLU</code></td>
<td>The activation function that should be used.</td>
</tr>
<tr>
<td><strong><code>initial_dilation</code></strong></td>
<td><code>int</code></td>
<td><code>None</code></td>
<td>The amount of dilation that should be used in the first encoding block.</td>
</tr>
<tr>
<td><strong><code>dropout</code></strong></td>
<td><code>float</code></td>
<td><code>0.0</code></td>
<td>The dropout rate.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Encoder.forward" class="doc_header"><code>Encoder.forward</code><a href="dl4to/models.py#L324" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Encoder.forward</code>(<strong><code>x</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>The forward pass of the encoder.
Returns a list of <code>torch.Tensors</code> that define the outputs of the skip connections, and a <code>torch.Tensor</code> that is the output of the encoder.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>x</code></strong></td>
<td><code>Tensor</code></td>
<td></td>
<td>The input of the encoder.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">References<a class="anchor-link" href="#References"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>[1] Falk, Thorsten, et al. "U-Net: deep learning for cell counting, detection, and morphometry." Nature methods 16.1 (2019): 67-70.</p>

</div>
</div>
</div>
</div>
 

