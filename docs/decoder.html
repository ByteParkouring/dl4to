---

title: Decoder


keywords: fastai
sidebar: home_sidebar



nb_path: "notebooks/models/2_decoder.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/models/2_decoder.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DecodingBlock" class="doc_header"><code>class</code> <code>DecodingBlock</code><a href="dl4to/models.py#L348" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DecodingBlock</code>(<strong><code>in_channels_skip_connection</code></strong>:<code>int</code>, <strong><code>dimensions</code></strong>:<code>int</code>, <strong><code>upsampling_type</code></strong>:<code>str</code>, <strong><code>normalization</code></strong>:<code>str</code>, <strong><code>preactivation</code></strong>:<code>bool</code>, <strong><code>residual</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>use_padding</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>padding_mode</code></strong>:<code>str</code>=<em><code>'zeros'</code></em>, <strong><code>activation</code></strong>:<code>str</code>=<em><code>'ReLU'</code></em>, <strong><code>dilation</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>dropout</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>upsample_recover_orig_size</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>This class defines a decoding block for the decoder.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>in_channels_skip_connection</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of input channels from the skip connections of the encoder.</td>
</tr>
<tr>
<td><strong><code>dimensions</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of dimensions to consider. Possible options are 2 and 3.</td>
</tr>
<tr>
<td><strong><code>upsampling_type</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of upsampling to use.</td>
</tr>
<tr>
<td><strong><code>normalization</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of normalization to use. Possible options include "batch", "layer" and "instance".</td>
</tr>
<tr>
<td><strong><code>preactivation</code></strong></td>
<td><code>bool</code></td>
<td></td>
<td>Whether to use preactivations.</td>
</tr>
<tr>
<td><strong><code>residual</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether the decoder should be a residual network.</td>
</tr>
<tr>
<td><strong><code>use_padding</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to use padding.</td>
</tr>
<tr>
<td><strong><code>padding_mode</code></strong></td>
<td><code>str</code></td>
<td><code>zeros</code></td>
<td>The type of padding to use.</td>
</tr>
<tr>
<td><strong><code>activation</code></strong></td>
<td><code>str</code></td>
<td><code>ReLU</code></td>
<td>The activation function that should be used.</td>
</tr>
<tr>
<td><strong><code>dilation</code></strong></td>
<td><code>int</code></td>
<td><code>None</code></td>
<td>The amount of dilation that should be used.</td>
</tr>
<tr>
<td><strong><code>dropout</code></strong></td>
<td><code>float</code></td>
<td><code>0.0</code></td>
<td>The dropout rate.</td>
</tr>
<tr>
<td><strong><code>upsample_recover_orig_size</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether the original input size of the encoder should be recovered with the decoder output.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="DecodingBlock.forward" class="doc_header"><code>DecodingBlock.forward</code><a href="dl4to/models.py#L425" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>DecodingBlock.forward</code>(<strong><code>skip_connection</code></strong>:<code>list</code>, <strong><code>x</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>The forward pass of the decoding block.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>skip_connection</code></strong></td>
<td><code>list</code></td>
<td></td>
<td>A list of <code>torch.Tensors</code> that contain the outputs of the skip connections from an encoding block.</td>
</tr>
<tr>
<td><strong><code>x</code></strong></td>
<td><code>Tensor</code></td>
<td></td>
<td>The input to the decoding block.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Decoder" class="doc_header"><code>class</code> <code>Decoder</code><a href="dl4to/models.py#L484" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Decoder</code>(<strong><code>in_channels_skip_connection</code></strong>:<code>int</code>, <strong><code>dimensions</code></strong>:<code>int</code>, <strong><code>upsampling_type</code></strong>:<code>str</code>, <strong><code>num_decoding_blocks</code></strong>:<code>int</code>, <strong><code>normalization</code></strong>:<code>str</code>, <strong><code>preactivation</code></strong>:<code>bool</code>, <strong><code>residual</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>use_padding</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>padding_mode</code></strong>:<code>str</code>=<em><code>'zeros'</code></em>, <strong><code>activation</code></strong>:<code>str</code>=<em><code>'ReLU'</code></em>, <strong><code>initial_dilation</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>dropout</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>upsample_recover_orig_size</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Defines a decoder that can be used for the construction of UNets [1].
The decoder is a neural network that takes the feature vector from the encoder and decodes it into an output.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>in_channels_skip_connection</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of input channels from the skip connections of the encoder.</td>
</tr>
<tr>
<td><strong><code>dimensions</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of dimensions to consider. Possible options are 2 and 3.</td>
</tr>
<tr>
<td><strong><code>upsampling_type</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of upsampling to use.</td>
</tr>
<tr>
<td><strong><code>num_decoding_blocks</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>The number of decoding blocks.</td>
</tr>
<tr>
<td><strong><code>normalization</code></strong></td>
<td><code>str</code></td>
<td></td>
<td>The type of normalization to use. Possible options include "batch", "layer" and "instance".</td>
</tr>
<tr>
<td><strong><code>preactivation</code></strong></td>
<td><code>bool</code></td>
<td></td>
<td>Whether to use preactivations.</td>
</tr>
<tr>
<td><strong><code>residual</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether the decoder should be a residual network.</td>
</tr>
<tr>
<td><strong><code>use_padding</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to use padding.</td>
</tr>
<tr>
<td><strong><code>padding_mode</code></strong></td>
<td><code>str</code></td>
<td><code>zeros</code></td>
<td>The type of padding to use.</td>
</tr>
<tr>
<td><strong><code>activation</code></strong></td>
<td><code>str</code></td>
<td><code>ReLU</code></td>
<td>The activation function that should be used.</td>
</tr>
<tr>
<td><strong><code>initial_dilation</code></strong></td>
<td><code>int</code></td>
<td><code>None</code></td>
<td>The amount of dilation that should be used in the first encoding block.</td>
</tr>
<tr>
<td><strong><code>dropout</code></strong></td>
<td><code>float</code></td>
<td><code>0.0</code></td>
<td>The dropout rate.</td>
</tr>
<tr>
<td><strong><code>upsample_recover_orig_size</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether the original input size of the encoder should be recovered with the decoder output.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Decoder.forward" class="doc_header"><code>Decoder.forward</code><a href="dl4to/models.py#L544" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Decoder.forward</code>(<strong><code>skip_connections</code></strong>:<code>list</code>, <strong><code>x</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>The forward pass of the decoder.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>skip_connections</code></strong></td>
<td><code>list</code></td>
<td></td>
<td>A list of <code>torch.Tensors</code> that contain the outputs of the skip connections from an encoder.</td>
</tr>
<tr>
<td><strong><code>x</code></strong></td>
<td><code>Tensor</code></td>
<td></td>
<td>The input to the decoder.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">References<a class="anchor-link" href="#References"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>[1] Falk, Thorsten, et al. "U-Net: deep learning for cell counting, detection, and morphometry." Nature methods 16.1 (2019): 67-70.</p>

</div>
</div>
</div>
</div>
 

