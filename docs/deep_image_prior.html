---

title: Deep Image Prior


keywords: fastai
sidebar: home_sidebar



nb_path: "notebooks/models/4_deep_image_prior.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/models/4_deep_image_prior.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DeepImagePrior" class="doc_header"><code>class</code> <code>DeepImagePrior</code><a href="dl4to/models.py#L759" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DeepImagePrior</code>(<strong><code>shape</code></strong>:<code>list</code>, <strong><code>n_channels</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>n_inital_channels</code></strong>:<code>int</code>=<em><code>4</code></em>) :: <code>Module</code></p>
</blockquote>
<p>The deep image prior (DIP) [1] is a type of convolutional neural network used to enhance a given image with no prior training data other than the image itself.
A neural network is randomly initialized and used as prior to solve inverse problems such as noise reduction, super-resolution, and inpainting.
Image statistics are captured by the structure of a convolutional image generator rather than by any previously learned capabilities.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>shape</code></strong></td>
<td><code>list</code></td>
<td></td>
<td>A list containing three entries that define the number of voxels in each direction.</td>
</tr>
<tr>
<td><strong><code>n_channels</code></strong></td>
<td><code>int</code></td>
<td><code>1</code></td>
<td>The number of input channels.</td>
</tr>
<tr>
<td><strong><code>n_inital_channels</code></strong></td>
<td><code>int</code></td>
<td><code>4</code></td>
<td>T he number of channels after the first encoding block. The model has a total 4 encoding and 4 decoding blocks, and the number of channels is doubled in each encoding step.</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="DeepImagePrior.forward" class="doc_header"><code>DeepImagePrior.forward</code><a href="dl4to/models.py#L789" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>DeepImagePrior.forward</code>()</p>
</blockquote>
<p>The forward pass of the DIP with a fixed random noise input. Returns a <code>torch.Tensor</code> object.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">References<a class="anchor-link" href="#References"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>[1] Ulyanov, Dmitry, Andrea Vedaldi, and Victor Lempitsky. "Deep image prior." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.</p>

</div>
</div>
</div>
</div>
 

